{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b69f9f4",
   "metadata": {},
   "source": [
    "# Create Datastore\n",
    "\n",
    "Create Datastore that connects to Azure blob container that contains raw text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd30eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Register a new datastore from blob container with raw data\n",
    "blob_store = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                  datastore_name='lis_artifacts', \n",
    "                                                  container_name='lis-artifacts',\n",
    "                                                  account_name='lisml8132196936',\n",
    "                                                  account_key='vhUtGVMoHyzG0NBy86EkG+WYjXUfTiDxhDZvy4mJr2I5e432Lq1ynpyXMAP5z6fxK2Zf/woO8L2n1FJIThx1lA==')\n",
    "\n",
    "blob_store = Datastore.get(ws, datastore_name='lis_artifacts')\n",
    "\n",
    "ws.set_default_datastore('lis_artifacts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211f33e",
   "metadata": {},
   "source": [
    "Upload csv files to datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a722e66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Target already exists. Skipping upload for data/train.csv\n",
      "Target already exists. Skipping upload for data/eval.csv\n",
      "Uploaded 0 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_ff0c89f895844ba2a61be9989fcb719b"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the local files from src_dir to the datastore\n",
    "\n",
    "blob_store.upload_files(files=['../data/train.csv', '../data/eval.csv'], target_path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db3b98d",
   "metadata": {},
   "source": [
    "# Create Components Directories\n",
    "\n",
    "Create a directory for the components of the pipeline. Create subdirectories for each component/step (train, register, deploy ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c65b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Set the directory for the experiment files \n",
    "components_dir = 'lis_components'\n",
    "os.makedirs(components_dir, exist_ok=True)\n",
    "\n",
    "# Create a directory inside for the train component\n",
    "os.makedirs(os.path.join(components_dir, \"train\"), exist_ok=True)\n",
    "# Create a directory inside for the register component\n",
    "os.makedirs(os.path.join(components_dir, \"register\"), exist_ok=True)\n",
    "# Create a directory inside for the deploy component\n",
    "os.makedirs(os.path.join(components_dir, \"deploy\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9244f",
   "metadata": {},
   "source": [
    "# Step 1: train.py\n",
    "\n",
    "This script train load a pretrained GPT2 model and fine tune the model over the train & eval datasets provided in the datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e0e8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/train/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/train/train.py\n",
    "\n",
    "import random\n",
    "import logging\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "from transformers import TFTrainingArguments, HfArgumentParser\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "from transformers import create_optimizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "#reload(logging)\n",
    "#logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "#logger = logging.getLogger()\n",
    "\n",
    "\n",
    "# region Command-line arguments\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str = field(\n",
    "        default=\"gpt2\",\n",
    "        metadata={\n",
    "            \"help\": \"The model checkpoint for weights initialization.\"\n",
    "        },\n",
    "    )\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        if self.model_name is None:\n",
    "            raise ValueError(\n",
    "                \"--cannot call script without model_name argument\"\n",
    "            )\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    train_file: str = field(default=\"data/train.csv\", metadata={\"help\": \"The input training data file (a csv file).\"})\n",
    "    eval_file: str = field(\n",
    "        default=\"data/eval.csv\",\n",
    "        metadata={\"help\": \"The input evaluation data file to evaluate the perplexity on (a csv file).\"},\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=True, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.train_file is None or self.eval_file is None:\n",
    "            raise ValueError(\n",
    "                \"--cannot call scripts without train_file & eval_file arguments\"\n",
    "            )\n",
    "\n",
    "def sample_generator(dataset, tokenizer):\n",
    "    # Trim off the last partial batch if present\n",
    "    sample_ordering = np.random.permutation(len(dataset))\n",
    "    for sample_idx in sample_ordering:\n",
    "        example = dataset[int(sample_idx)]\n",
    "        # Handle dicts with proper padding and conversion to tensor.\n",
    "        example = {key: tf.convert_to_tensor(arr, dtype_hint=tf.int64) for key, arr in example.items()}\n",
    "        yield example, example[\"labels\"]  # TF needs some kind of labels, even if we don't use them\n",
    "    return\n",
    "\n",
    "# region Helper classes\n",
    "class SavePretrainedCallback(tf.keras.callbacks.Callback):\n",
    "    # Hugging Face models have a save_pretrained() method that saves both the weights and the necessary\n",
    "    # metadata to allow them to be loaded as a pretrained model in future. This is a simple Keras callback\n",
    "    # that saves the model with this method after each epoch.\n",
    "    def __init__(self, output_dir, **kwargs):\n",
    "        super().__init__()\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.save_pretrained(self.output_dir)\n",
    "        \n",
    "        \n",
    "def main():\n",
    "    # region Argument Parsing\n",
    "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TFTrainingArguments))\n",
    "\n",
    "    # region Setup logging\n",
    "    #logger.setLevel(logging.INFO)\n",
    "    \n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "    # Load the dataset from the datastore.\n",
    "    raw_datasets = load_dataset('csv', data_files={'train': data_args.train_file, 'test': data_args.eval_file})\n",
    "\n",
    "    # Testing loading datasets\n",
    "    index = random.sample(range(len(raw_datasets[\"train\"])), 1)\n",
    "    #logger.info(f\"  Example raw dataset: %s\", raw_datasets[\"train\"][index])\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_args.model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name)\n",
    "\n",
    "    text_column_name = \"text\"\n",
    "    column_names = raw_datasets[\"train\"].column_names\n",
    "    \n",
    "    # Preprocess Dataset & add eos_token \n",
    "    # Main data processing function that will add eos_token to each text in the dataset\n",
    "    def add_eos_token(examples):\n",
    "        examples_with_eos = examples\n",
    "        examples_with_eos[text_column_name] = [x + tokenizer.eos_token for x in examples[text_column_name]]  \n",
    "        return examples_with_eos\n",
    "\n",
    "    raw_datasets = raw_datasets.map(\n",
    "        add_eos_token,\n",
    "        batched=True,\n",
    "        num_proc=data_args.preprocessing_num_workers,\n",
    "        load_from_cache_file=not data_args.overwrite_cache,\n",
    "        desc=f\"Adding eos_token to each example in the dataset\",\n",
    "    )\n",
    "    \n",
    "    # Testing preprocess\n",
    "    #logger.info(f\"  Example raw dataset with eos token: %s\", raw_datasets[\"train\"][index])\n",
    "\n",
    "    ## Tokenize dataset using gpt2 tokenizer\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[text_column_name])\n",
    "\n",
    "    tokenized_datasets = raw_datasets.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        num_proc=data_args.preprocessing_num_workers,\n",
    "        remove_columns=column_names,\n",
    "        load_from_cache_file=not data_args.overwrite_cache,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "    \n",
    "    # Testing Tokenization\n",
    "    #logger.info(f\"  Example tokenized dataset: %s\", tokenized_datasets[\"train\"][index])\n",
    "\n",
    "    # Concatenate all texts from our dataset and generate chunks of block_size\n",
    "    \n",
    "    block_size = tokenizer.model_max_length\n",
    "    if block_size > 1024:\n",
    "        # The tokenizer picked seems to have a very large `model_max_length`\n",
    "        block_size = 1024\n",
    "\n",
    "    # Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.\n",
    "    def group_texts(examples):\n",
    "        # Concatenate all texts.\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "        if total_length >= block_size:\n",
    "            total_length = (total_length // block_size) * block_size\n",
    "        # Split by chunks of max_len.\n",
    "        result = {\n",
    "            k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "\n",
    "    lm_datasets = tokenized_datasets.map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        batch_size=len(tokenized_datasets[\"train\"]), # if training size is very small, like in our case.\n",
    "        num_proc=data_args.preprocessing_num_workers,\n",
    "        load_from_cache_file=not data_args.overwrite_cache,\n",
    "        desc=f\"Grouping texts in chunks of {block_size}\",\n",
    "    )\n",
    "    \n",
    "    # Testing Grouping Texts\n",
    "    \n",
    "    #logger.info(f\"  Example 0 raw dataset: %s\", raw_datasets[\"train\"][0])\n",
    "    #logger.info(f\"  Example 0 raw dataset: %s\", raw_datasets[\"train\"][1])\n",
    "    #logger.info(f\"  Example 0 raw dataset: %s\", raw_datasets[\"train\"][2])\n",
    "    #logger.info(f\"  Example 0 raw dataset: %s\", raw_datasets[\"train\"][3])\n",
    "\n",
    "    #logger.info(f\"  Example 0 tokenized dataset: %s\", tokenized_datasets[\"train\"][0])\n",
    "    #logger.info(f\"  Example 0 tokenized dataset: %s\", tokenized_datasets[\"train\"][1])\n",
    "    #logger.info(f\"  Example 0 tokenized dataset: %s\", tokenized_datasets[\"train\"][2])\n",
    "    #logger.info(f\"  Example 0 tokenized dataset: %s\", tokenized_datasets[\"train\"][3])\n",
    "\n",
    "   \n",
    "    #logger.info(f\"  Example 0 concatenated tokenized dataset: %s\", lm_datasets[\"train\"][0]['input_ids'][:40])\n",
    "\n",
    "    \n",
    "    # Prepare Training & Evaluation Datasets\n",
    "    train_dataset = lm_datasets[\"train\"]\n",
    "    eval_dataset = lm_datasets[\"test\"]\n",
    "    \n",
    "    if data_args.max_train_samples is not None:\n",
    "        train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "    if data_args.max_eval_samples is not None:\n",
    "        eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n",
    "        \n",
    "    # Logging Training Parameters\n",
    "    \n",
    "    num_replicas = training_args.strategy.num_replicas_in_sync\n",
    "    batches_per_epoch = len(train_dataset) // (num_replicas * training_args.per_device_train_batch_size)\n",
    "    \"\"\"\n",
    "    logger.info(f\"  Training Arguments: %s\",\n",
    "    {\n",
    "        \"init_lr\": training_args.learning_rate,\n",
    "        \"num_replicas\": num_replicas,\n",
    "        \"strategy\": training_args.strategy,\n",
    "        \"num_train_epochs\": training_args.num_train_epochs,\n",
    "        \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"batches_per_epoch\": len(train_dataset) // (num_replicas * training_args.per_device_train_batch_size),\n",
    "        \"num_train_steps\": int(training_args.num_train_epochs * batches_per_epoch),\n",
    "        \"num_warmup_steps\": training_args.warmup_steps,\n",
    "        \"adam_beta1\": training_args.adam_beta1,\n",
    "        \"adam_beta2\": training_args.adam_beta2,\n",
    "        \"adam_epsilon\": training_args.adam_epsilon,\n",
    "        \"weight_decay_rate\": training_args.weight_decay\n",
    "    }\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Train Model\n",
    "\n",
    "    with training_args.strategy.scope():\n",
    "\n",
    "        config = AutoConfig.from_pretrained(model_args.model_name)\n",
    "        model = TFAutoModelForCausalLM.from_pretrained(model_args.model_name, config=config)\n",
    "\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        num_replicas = training_args.strategy.num_replicas_in_sync\n",
    "\n",
    "        # region TF Dataset preparation\n",
    "        train_generator = partial(sample_generator, train_dataset, tokenizer)\n",
    "        train_signature = {\n",
    "            feature: tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
    "            for feature in train_dataset.features\n",
    "            if feature != \"special_tokens_mask\"\n",
    "        }\n",
    "        train_sig = (train_signature, train_signature[\"labels\"])\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "        tf_train_dataset = (\n",
    "            tf.data.Dataset.from_generator(train_generator, output_signature=train_sig)\n",
    "            .with_options(options)\n",
    "            .batch(batch_size=num_replicas * training_args.per_device_train_batch_size, drop_remainder=True)\n",
    "            .repeat(int(training_args.num_train_epochs))\n",
    "        )\n",
    "        eval_generator = partial(sample_generator, eval_dataset, tokenizer)\n",
    "        eval_signature = {\n",
    "            feature: tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
    "            for feature in eval_dataset.features\n",
    "            if feature != \"special_tokens_mask\"\n",
    "        }\n",
    "        eval_sig = (eval_signature, eval_signature[\"labels\"])\n",
    "        tf_eval_dataset = (\n",
    "            tf.data.Dataset.from_generator(eval_generator, output_signature=eval_sig)\n",
    "            .with_options(options)\n",
    "            .batch(batch_size=num_replicas * training_args.per_device_eval_batch_size, drop_remainder=True)\n",
    "            .repeat(int(training_args.num_train_epochs))\n",
    "        )\n",
    "        # endregion\n",
    "        # region Optimizer and loss\n",
    "\n",
    "        batches_per_epoch = len(train_dataset) // (num_replicas * training_args.per_device_train_batch_size)\n",
    "        # Bias and layernorm weights are automatically excluded from the decay\n",
    "        optimizer, lr_schedule = create_optimizer(\n",
    "            init_lr=training_args.learning_rate,\n",
    "            num_train_steps=int(training_args.num_train_epochs * batches_per_epoch),\n",
    "            num_warmup_steps=training_args.warmup_steps,\n",
    "            adam_beta1=training_args.adam_beta1,\n",
    "            adam_beta2=training_args.adam_beta2,\n",
    "            adam_epsilon=training_args.adam_epsilon,\n",
    "            weight_decay_rate=training_args.weight_decay,\n",
    "        )\n",
    "\n",
    "        def dummy_loss(y_true, y_pred):\n",
    "            return tf.reduce_mean(y_pred)\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss={\"loss\": dummy_loss})\n",
    "        # endregion\n",
    "\n",
    "        # region Training and validation\n",
    "        #logger.info(\"***** Running training *****\")\n",
    "        #logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "        #logger.info(f\"  Num Epochs = {training_args.num_train_epochs}\")\n",
    "        #logger.info(f\"  Instantaneous batch size per device = {training_args.per_device_train_batch_size}\")\n",
    "        #logger.info(f\"  Total train batch size = {training_args.per_device_train_batch_size * num_replicas}\")\n",
    "\n",
    "        history = model.fit(\n",
    "            tf_train_dataset,\n",
    "            validation_data=tf_eval_dataset,\n",
    "            epochs=int(training_args.num_train_epochs),\n",
    "            steps_per_epoch=len(train_dataset) // (training_args.per_device_train_batch_size * num_replicas),\n",
    "            callbacks=[SavePretrainedCallback(output_dir=training_args.output_dir)],\n",
    "        )\n",
    "        try:\n",
    "            train_perplexity = math.exp(history.history[\"loss\"][-1])\n",
    "        except OverflowError:\n",
    "            train_perplexity = math.inf\n",
    "        try:\n",
    "            validation_perplexity = math.exp(history.history[\"val_loss\"][-1])\n",
    "        except OverflowError:\n",
    "            validation_perplexity = math.inf\n",
    "        #logger.info(f\"  Final train loss: {history.history['loss'][-1]:.3f}\")\n",
    "        #logger.info(f\"  Final train perplexity: {train_perplexity:.3f}\")\n",
    "        #logger.info(f\"  Final validation loss: {history.history['val_loss'][-1]:.3f}\")\n",
    "        #logger.info(f\"  Final validation perplexity: {validation_perplexity:.3f}\")\n",
    "        # endregion\n",
    "        \n",
    "        # log metrics to AML\n",
    "        run = Run.get_context()\n",
    "\n",
    "        run.log(\"Final train loss\", history.history['loss'][-1])\n",
    "        run.log(\"Final validation loss\", history.history['val_loss'][-1])\n",
    "        run.log(\"Final train perplexity\", train_perplexity)\n",
    "        run.log(\"Final validation perplexity\", validation_perplexity)\n",
    "\n",
    "        run.parent.log(\"Final train loss\", history.history['loss'][-1])\n",
    "        run.parent.log(\"Final validation loss\", history.history['val_loss'][-1])\n",
    "        run.parent.log(\"Final train perplexity\", train_perplexity)\n",
    "        run.parent.log(\"Final validation perplexity\", validation_perplexity)\n",
    "                \n",
    "        if training_args.output_dir is not None:\n",
    "            model.save_pretrained(training_args.output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdc162",
   "metadata": {},
   "source": [
    "# Step 2: register.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f64549",
   "metadata": {},
   "source": [
    "This script uploads the saved h5 model from the blob store and register it as an AML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b1e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/register/register.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/register/register.py\n",
    "\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "\n",
    "def main():\n",
    "    # Get parameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_dir', \n",
    "                        type=str, \n",
    "                        dest='model_dir', \n",
    "                        default=\"outputs\",\n",
    "                        help='model location')\n",
    "    parser.add_argument(\"--model_name\",\n",
    "                        type=str,\n",
    "                        help=\"Name of the Registered Model\",\n",
    "                        default=\"lis-gpt2-model\")\n",
    "    parser.add_argument(\"--register_deploy_link\",\n",
    "                        type=str,\n",
    "                        help=\"register_deploy_link\",\n",
    "                        default=\"register_deploy_link\")\n",
    "\n",
    "   \n",
    "    args = parser.parse_args()\n",
    "    model_dir = args.model_dir\n",
    "    model_name = args.model_name\n",
    "\n",
    "    # Get the experiment run context\n",
    "    run = Run.get_context()\n",
    "\n",
    "    # load the model\n",
    "    print(\"Loading model from \" + model_dir)\n",
    "    model_file = os.path.join(model_dir, \"tf_model.h5\")\n",
    "    model_config_file = os.path.join(model_dir, \"config.json\")\n",
    "\n",
    "    # Get metrics for registration\n",
    "    metrics = run.parent.get_metrics()\n",
    "\n",
    "    # Register the model\n",
    "    run.upload_file(\"outputs/tf_model.h5\", model_file)\n",
    "    run.upload_file(\"outputs/config.json\", model_config_file)\n",
    "    \n",
    "    run.register_model(\n",
    "        model_path=\"outputs/\",\n",
    "        model_name=model_name,\n",
    "        tags=metrics)\n",
    "\n",
    "    run.complete()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9122149",
   "metadata": {},
   "source": [
    "# Step 3: deploy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4db8d",
   "metadata": {},
   "source": [
    "This step needs two scripts:\n",
    "\n",
    "A script deploy.py that will use azureml api to deploy an ACIservice. \n",
    "\n",
    "A script score.py that will be used by the service to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803345fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/deploy/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/deploy/score.py\n",
    "\n",
    "import json\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    ## TODO\n",
    "    global model, tokenizer\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('lis-gpt2-model')    \n",
    "    model = TFGPT2LMHeadModel.from_pretrained(model_path)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "\n",
    "    input_ids = tokenizer.encode(json.loads(raw_data)['data'], return_tensors='tf')\n",
    "\n",
    "    generated_text_samples = model.generate(\n",
    "        input_ids, \n",
    "        max_length=30,  \n",
    "        num_return_sequences=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        do_sample=True,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    json_output = {}\n",
    "    for i, beam in enumerate(generated_text_samples):\n",
    "        json_output[i+1] = tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        \n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e90ebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/deploy/deploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/deploy/deploy.py\n",
    "\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    # Get parameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--service_name\",\n",
    "                        type=str,\n",
    "                        help=\"Name of the Web Service\",\n",
    "                        default=\"lis-gpt2-webservice\")\n",
    "    parser.add_argument(\"--model_name\",\n",
    "                        type=str,\n",
    "                        help=\"Name of the registered model name\",\n",
    "                        default=\"lis-gpt2-model\")\n",
    "    parser.add_argument(\"--cpu_cores\",\n",
    "                        type=int,\n",
    "                        help=\"CPU reserve capacity\",\n",
    "                        default=1)\n",
    "    parser.add_argument(\"--memory_gb\",\n",
    "                        type=float,\n",
    "                        help=\"Memory reserve capacity\",\n",
    "                        default=2)\n",
    "    parser.add_argument(\"--register_deploy_link\",\n",
    "                        type=str,\n",
    "                        help=\"register_deploy_link\",\n",
    "                        default=\"register_deploy_link\")\n",
    "    args = parser.parse_args()\n",
    "    service_name = args.service_name\n",
    "    model_name = args.model_name\n",
    "    cpu_cores = args.cpu_cores\n",
    "    memory_gb = args.memory_gb    \n",
    "    components_dir = \"lis_components\"\n",
    "    \n",
    "    # Configure the scoring environment\n",
    "    inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                       entry_script=os.path.join(components_dir, \"deploy\", \"score.py\"),\n",
    "                                       conda_file=os.path.join(components_dir, \"dependencies_scoring.yml\"))\n",
    "\n",
    "    deployment_config = AciWebservice.deploy_configuration(cpu_cores = cpu_cores, memory_gb = memory_gb)\n",
    "    \n",
    "    # Get the experiment run context\n",
    "    run = Run.get_context()\n",
    "    ws = run.experiment.workspace\n",
    "    \n",
    "    model = ws.models[model_name]\n",
    "    print(model.name, 'version', model.version)\n",
    "\n",
    "    service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "    service.wait_for_deployment(True)\n",
    "    \n",
    "    print(service.state)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697fad16",
   "metadata": {},
   "source": [
    "# Create dependencies.yml\n",
    "\n",
    "Define an environment YAML file with the components steps script dependencies and create an Azure ML environment for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95352d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/dependencies.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/dependencies.yml\n",
    "\n",
    "name: lis_env\n",
    "    \n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML Workbench only supports 3.5.2 and later.\n",
    "  - python=3.6.9\n",
    "  - pip\n",
    "\n",
    "  - pip:\n",
    "      - transformers == 3.5.1\n",
    "      - datasets == 1.10.2\n",
    "      - tensorflow == 2.5.0\n",
    "      - azureml-defaults==1.30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d3710f",
   "metadata": {},
   "source": [
    "# Create dependencies_scoring.yml\n",
    "\n",
    "Define an environment YAML file with dependencies for the web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a04eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/dependencies_scoring.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/dependencies_scoring.yml\n",
    "\n",
    "name: lis_env_scoring\n",
    "    \n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML Workbench only supports 3.5.2 and later.\n",
    "  - python=3.6.9\n",
    "  - pip\n",
    "\n",
    "  - pip:\n",
    "      - transformers == 3.5.1\n",
    "      - tensorflow == 2.5.0\n",
    "      - azureml-defaults==1.30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06028a0",
   "metadata": {},
   "source": [
    "# Create an Azure Machine Learning Pipeline to Run the Scripts as a Pipeline¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b4522ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2a8ea7",
   "metadata": {},
   "source": [
    "## Prepare a Compute Environment for the Pipeline Steps\n",
    "\n",
    "Create a compute target for training your model. We use Azure ML managed compute (AmlCompute) for remote compute resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583d6991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"pipeline-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a804e",
   "metadata": {},
   "source": [
    "# Prepare Pipeline Envirnoment\n",
    "\n",
    "Prepare Pipeline environment, python dependencies & compute used by aml pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd801a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the pipeline experiment\n",
    "pipeline_environment = Environment.from_conda_specification(name = 'pipeline-env', \n",
    "                                                          file_path = os.path.join(components_dir, \n",
    "                                                                                   \"dependencies.yml\"))\n",
    "pipeline_environment.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "pipeline_environment.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = pipeline_environment\n",
    "\n",
    "print (\"Pipeline configuration created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e012bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "\n",
    "# train_file, eval_file and output_file are passed as a datastore path between steps\n",
    "train_datastore_path = DataReference(data_reference_name = \"train_datastore_path\", datastore=ws.datastores['lis_artifacts'], path_on_datastore = \"data/train.csv\")\n",
    "eval_datastore_path = DataReference(data_reference_name = \"eval_datastore_path\", datastore=ws.datastores['lis_artifacts'], path_on_datastore = \"data/eval.csv\")\n",
    "output_datastore_path = OutputFileDatasetConfig(\"output_datastore_path\", destination=(ws.datastores['lis_artifacts'], \"outputs\")).as_mount()\n",
    "\n",
    "num_train_epochs_param = PipelineParameter(name=\"num_train_epochs\", default_value=3)\n",
    "\n",
    "aml_model_name_param = PipelineParameter(name=\"aml_model_name\", default_value=\"lis-gpt2-model\")\n",
    "register_deploy_link = PipelineData(\"register_deploy_link\")\n",
    "\n",
    "aml_service_name_param = PipelineParameter(name=\"aml_service_name\", default_value=\"lis-gpt2-serviceapp\")\n",
    "cpu_cores_param = PipelineParameter(name=\"cpu_cores\", default_value=1)\n",
    "memory_gb_param = PipelineParameter(name=\"memory_gb\", default_value=2)\n",
    "    \n",
    "    \n",
    "# Create Step 1, which runs the PythonScriptStep to train / finetune\n",
    "train_step = PythonScriptStep(name = \"Train\",\n",
    "                                source_directory = \".\",\n",
    "                                script_name = os.path.join(components_dir, \"train/train.py\"),\n",
    "                                arguments=['--model_name', \"gpt2\", \n",
    "                                           '--output_dir', output_datastore_path,\n",
    "                                           '--train_file', train_datastore_path,\n",
    "                                           '--eval_file', eval_datastore_path,\n",
    "                                           '--num_train_epochs', num_train_epochs_param,\n",
    "                                           '--max_train_samples', 8,\n",
    "                                           '--max_eval_samples', 8,\n",
    "                                           #'--per_gpu_train_batch_size', 8,  \n",
    "                                           #'--per_gpu_eval_batch_size', 8, \n",
    "                                           #'--fp16'\n",
    "                                          ],\n",
    "                                inputs=[train_datastore_path, eval_datastore_path],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = False)\n",
    "\n",
    "# Create Step 2, which runs the PythonScriptStep to register model\n",
    "register_step = PythonScriptStep(name = \"Register\",\n",
    "                                source_directory = \".\",\n",
    "                                script_name = os.path.join(components_dir, \"register/register.py\"),\n",
    "                                arguments=['--model_name', aml_model_name_param, \n",
    "                                           '--model_dir', output_datastore_path.as_input(),\n",
    "                                           '--register_deploy_link', register_deploy_link\n",
    "                                          ],\n",
    "                                outputs=[register_deploy_link],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = False)\n",
    "\n",
    "# Create Step 3, which runs the PythonScriptStep to deploy model as a web service\n",
    "deploy_step = PythonScriptStep(name = \"Deploy\",\n",
    "                                source_directory = \".\",\n",
    "                                script_name = os.path.join(components_dir, \"deploy/deploy.py\"),\n",
    "                                arguments=['--service_name', aml_service_name_param, \n",
    "                                           '--model_name', aml_model_name_param, \n",
    "                                           '--cpu_cores', cpu_cores_param,\n",
    "                                           '--memory_gb', memory_gb_param,\n",
    "                                           '--register_deploy_link', register_deploy_link\n",
    "                                          ],\n",
    "                                inputs=[register_deploy_link],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274306f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [train_step, register_step, deploy_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa5d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Train [17b50458][9d96330e-3873-4610-83b7-957b4016babf], (This step will run and generate new outputs)\n",
      "Created step Register [ab43254f][ff9b1db8-f8bf-4c25-8b71-70de214e2b41], (This step will run and generate new outputs)\n",
      "Created step Deploy [25177c8c][0ac4e4a0-8edc-497f-a572-a64a8ac862b6], (This step will run and generate new outputs)\n",
      "Using data reference train_datastore_path for StepId [7bea0512][ab4bddc8-5eb4-4709-ad5c-dc555df7d52f], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference eval_datastore_path for StepId [e56fbf22][197693d2-331a-4bf3-a2b4-c18bf5d4bb63], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted PipelineRun f29233bb-ae00-4b8c-bf50-7e1cd833cd29\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f29233bb-ae00-4b8c-bf50-7e1cd833cd29?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Pipeline submitted for execution.\n",
      "PipelineRunId: f29233bb-ae00-4b8c-bf50-7e1cd833cd29\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f29233bb-ae00-4b8c-bf50-7e1cd833cd29?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/87808ff9-f9b8-4808-b68c-a9a848478c4e?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Train ) Status: NotStarted\n",
      "StepRun( Train ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "========================================================================================================================\n",
      "2021-08-09T23:09:33Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-08-09T23:09:33Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore\n",
      "2021-08-09T23:09:33Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/caches/lis_artifacts --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/configs/lis_artifacts.cfg --log-level=LOG_WARNING\n",
      "2021-08-09T23:09:34Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts\n",
      "2021-08-09T23:09:34Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-08-09T23:09:34Z Starting output-watcher...\n",
      "2021-08-09T23:09:34Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-08-09T23:09:34Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-09T23:09:34Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_5572ea249a896c3014db8569f38d4a1a\n",
      "Digest: sha256:e4fcde8761b0dca23a91150bd7745746e90d05fb0e676a7adfc7e6fce5b6ce18\n",
      "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a:latest\n",
      "2021-08-09T23:09:35Z Check if container 87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar already exist exited with 0, \n",
      "\n",
      "414399043f1625ddca50a1659aa8ec18c4f3e7e87fb3bdf21a7b34cfbcbdceb9\n",
      "2021-08-09T23:09:35Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-09T23:09:35Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-e16fe67547554bc85a1680e5b70637b1-12fc2ddffc9e562f-01 -sshRequired=false] \n",
      "2021/08/09 23:09:35 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/09 23:09:35 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/09 23:09:35 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/09 23:09:35 Starting infiniband setup\n",
      "2021/08/09 23:09:35 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/09 23:09:35 Returning Python Version as 3.7\n",
      "2021-08-09T23:09:35Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/09 23:09:35 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/09 23:09:35 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/09 23:09:35 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-08-09T23:09:35Z Not setting up Infiniband in Container\n",
      "2021/08/09 23:09:35 Not setting up Infiniband in Container\n",
      "2021/08/09 23:09:35 Not setting up Infiniband in Container\n",
      "2021/08/09 23:09:35 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/09 23:09:35 Returning Python Version as 3.7\n",
      "2021/08/09 23:09:35 sshd inside container not required for job, skipping setup.\n",
      "2021/08/09 23:09:36 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/09 23:09:36 App Insight Client has already been closed\n",
      "2021/08/09 23:09:36 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-09T23:09:36Z Starting docker container succeeded.\n",
      "2021-08-09T23:09:47Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-09T23:09:47Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      "Digest: sha256:64071389a06820223142eabd61e1b4bfd5e0b450131c8a50eef3c745fad8a73e\n",
      "Status: Image is up to date for 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff:latest\n",
      "29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff:latest\n",
      "2021-08-09T23:09:47Z Check if container 87808ff9-f9b8-4808-b68c-a9a848478c4e already exist exited with 0, 414399043f16\n",
      "\n",
      "\n",
      "2021-08-09T23:09:47Z The container 87808ff9-f9b8-4808-b68c-a9a848478c4e already exists, stop and remove it before starting it.\n",
      "2021-08-09T23:09:47Z Stopping container 87808ff9-f9b8-4808-b68c-a9a848478c4e exited with 1, Error response from daemon: No such container: 87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      "\n",
      "\n",
      "2021-08-09T23:09:47Z Removing container 87808ff9-f9b8-4808-b68c-a9a848478c4e exited with 1, Error: No such container: 87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      "\n",
      "\n",
      "c1e0f5f84038a576f6aed7d9c9114835e4d4badd79a889a4500c356c2537c24d\n",
      "2021-08-09T23:09:48Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-09T23:09:48Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-e16fe67547554bc85a1680e5b70637b1-b53dac55099e6448-01 -sshRequired=false] \n",
      "2021/08/09 23:09:48 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/09 23:09:48 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/09 23:09:48 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/09 23:09:48 Starting infiniband setup\n",
      "2021/08/09 23:09:48 Python Version found is Python 3.6.9 :: Anaconda, Inc.\n",
      "\n",
      "2021/08/09 23:09:48 Returning Python Version as 3.6\n",
      "2021-08-09T23:09:48Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/09 23:09:48 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/09 23:09:48 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/09 23:09:48 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-08-09T23:09:48Z Not setting up Infiniband in Container\n",
      "2021/08/09 23:09:48 Not setting up Infiniband in Container\n",
      "2021/08/09 23:09:48 Not setting up Infiniband in Container\n",
      "2021/08/09 23:09:48 Python Version found is Python 3.6.9 :: Anaconda, Inc.\n",
      "\n",
      "2021/08/09 23:09:48 Returning Python Version as 3.6\n",
      "2021/08/09 23:09:48 sshd inside container not required for job, skipping setup.\n",
      "2021/08/09 23:09:48 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/09 23:09:48 App Insight Client has already been closed\n",
      "2021/08/09 23:09:48 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-09T23:09:48Z Starting docker container succeeded.\n",
      "2021-08-09T23:09:49Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/08/09 23:09:33 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/08/09 23:09:33 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      ">>>   2021/08/09 23:09:33 runtime.GOOS linux\n",
      ">>>   2021/08/09 23:09:33 Checking if '/tmp' exists\n",
      ">>>   2021/08/09 23:09:33 Reading dyanamic configs\n",
      ">>>   2021/08/09 23:09:33 Container sas url: https://baiscriptswesteuropeprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=9UBH7ig8b9NIeIkNQpNxDmP7wUMtSqFoIE5AY22cheE%3D\n",
      ">>>   2021/08/09 23:09:33 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n",
      ">>>   2021/08/09 23:09:33 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: true. Is Azsecpack installation enabled: false,\n",
      ">>>   2021/08/09 23:09:33 Starting Azsecpack installation on machine: f585a493cfbe4c568aa6cd957b0778e8000000#72f988bf-86f1-41af-91ab-2d7cd011db47#2f091423-f84d-4062-8e67-1437a0c50045#lis#lis-ml#pipeline-cluster#tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d\n",
      ">>>   2021/08/09 23:09:33 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n",
      ">>>   2021/08/09 23:09:33 Turning off azsecpack, if it is already running\n",
      ">>>   2021/08/09 23:09:33 [doTurnOffAzsecpack] output:Unit mdsd.service could not be found.\n",
      ">>>   ,err:exit status 1.\n",
      ">>>   2021/08/09 23:09:33 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/08/09 23:09:33 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/08/09 23:09:33 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/09 23:09:33 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/09 23:09:33 GPU count found on the node: 1\n",
      ">>>   2021/08/09 23:09:33 Mellanox Inbox drivers found (implying presence of SR-IOV)?: false\n",
      ">>>   2021/08/09 23:09:33 Disabling IB for NCCL.\n",
      ">>>   2021/08/09 23:09:33 AMLComputeXDSEndpoint:  https://westeurope-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/08/09 23:09:33 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/08/09 23:09:33 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config\n",
      ">>>   2021/08/09 23:09:33 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/08/09 23:09:33 Starting identity responder.\n",
      ">>>   2021/08/09 23:09:33 Starting identity responder.\n",
      ">>>   2021/08/09 23:09:33 Logfile used for identity responder: /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/IdentityResponderLog-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:09:33 Logfile used for identity responder: /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/IdentityResponderLog-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:09:33 Started Identity Responder for job.\n",
      ">>>   2021/08/09 23:09:33 Started Identity Responder for job.\n",
      ">>>   2021/08/09 23:09:33 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd\n",
      ">>>   2021/08/09 23:09:33 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/shared\n",
      ">>>   2021/08/09 23:09:33 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/08/09 23:09:33 Mounting job level file systems\n",
      ">>>   2021/08/09 23:09:33 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts\n",
      ">>>   2021/08/09 23:09:33 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/08/09 23:09:33 Datastore credentials file not found, skipping.\n",
      ">>>   2021/08/09 23:09:33 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.master.runtimesastokens\n",
      ">>>   2021/08/09 23:09:33 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/08/09 23:09:33 Mounting NFS servers\n",
      ">>>   2021/08/09 23:09:33 No Azure File Shares configured\n",
      ">>>   2021/08/09 23:09:33 Mounting blob file systems\n",
      ">>>   2021/08/09 23:09:33 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/08/09 23:09:33 Mounting azureml-blobstore-29bfa99a-8943-410c-8e02-10fa3a3417f5 container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore\n",
      ">>>   2021/08/09 23:09:33 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/09 23:09:33 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/09 23:09:33 Blobfuse cache size set to 312241 MB.\n",
      ">>>   2021/08/09 23:09:33 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/08/09 23:09:33 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore\n",
      ">>>   2021/08/09 23:09:33 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore\n",
      ">>>   2021/08/09 23:09:33 Successfully mounted azureml-blobstore-29bfa99a-8943-410c-8e02-10fa3a3417f5 container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore\n",
      ">>>   2021/08/09 23:09:33 Failed to created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e, due to mkdir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e: read-only file system\n",
      ">>>   2021/08/09 23:09:33 Mounting lis-artifacts container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts\n",
      ">>>   2021/08/09 23:09:33 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/09 23:09:33 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/09 23:09:33 Blobfuse cache size set to 312241 MB.\n",
      ">>>   2021/08/09 23:09:33 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/caches/lis_artifacts --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/configs/lis_artifacts.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/08/09 23:09:34 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts\n",
      ">>>   2021/08/09 23:09:34 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts\n",
      ">>>   2021/08/09 23:09:34 Successfully mounted lis-artifacts container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts\n",
      ">>>   2021/08/09 23:09:34 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   2021/08/09 23:09:34 No unmanaged file systems configured\n",
      ">>>   2021/08/09 23:09:34 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/09 23:09:34 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/09 23:09:34 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      ">>>   2021/08/09 23:09:34 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      ">>>   2021/08/09 23:09:34 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/08/09 23:09:34 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   2021/08/09 23:09:34 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   2021/08/09 23:09:34 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   2021/08/09 23:09:34 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   2021/08/09 23:09:34 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs\n",
      ">>>   2021/08/09 23:09:34 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d\n",
      ">>>   2021/08/09 23:09:34 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:09:34 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   2021/08/09 23:09:34 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs\n",
      ">>>   2021/08/09 23:09:34 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs\n",
      ">>>   2021/08/09 23:09:34 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs\n",
      ">>>   2021/08/09 23:09:34 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d\n",
      ">>>   2021/08/09 23:09:34 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:09:34 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs\n",
      ">>>   2021/08/09 23:09:34 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/logs\n",
      ">>>   2021/08/09 23:09:34 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/outputs\n",
      ">>>   2021/08/09 23:09:34 Starting output-watcher...\n",
      ">>>   2021/08/09 23:09:34 Single file input dataset is enabled.\n",
      ">>>   2021/08/09 23:09:34 Begin Sidecar setup\n",
      ">>>   2021/08/09 23:09:34 SingleDataDirectory enabled, Passing to Sidecar.\n",
      ">>>   2021/08/09 23:09:34 Pulling Sidecar docker image: azureml/azureml_5572ea249a896c3014db8569f38d4a1a\n",
      ">>>   2021/08/09 23:09:34 Start pull docker image: azureml\n",
      ">>>   2021/08/09 23:09:34 Getting credentials for image azureml/azureml_5572ea249a896c3014db8569f38d4a1a with url \n",
      ">>>   2021/08/09 23:09:34 Container registry is not ACR.\n",
      ">>>   2021/08/09 23:09:34 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/08/09 23:09:34 Getting ACR Credentials from EMS for environment AzureML-Sidecar:22\n",
      ">>>   2021/08/09 23:09:34 Requesting XDS for registry details.\n",
      ">>>   2021/08/09 23:09:34 Attempt 1 of http call to https://westeurope-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourceGroups/lis/workspaces/lis-ml/clusters/pipeline-cluster/nodes/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d?api-version=2018-02-01\n",
      ">>>   2021/08/09 23:09:34 Got container registry details from credentials service for registry address: viennaglobal.azurecr.io.\n",
      ">>>   2021/08/09 23:09:34 Writing ACR Details to file...\n",
      ">>>   2021/08/09 23:09:34 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/08/09 23:09:34 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/08/09 23:09:34 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/08/09 23:09:34 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/08/09 23:09:34 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/08/09 23:09:34 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/08/09 23:09:34 EMS returned viennaglobal.azurecr.io for environment AzureML-Sidecar\n",
      ">>>   2021/08/09 23:09:34 Updating image url from blank to viennaglobal.azurecr.io\n",
      ">>>   2021/08/09 23:09:34 Save docker credentials for image viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a in /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/docker_login_7FAF328B0632D63B\n",
      ">>>   2021/08/09 23:09:34 Start login to the docker registry\n",
      ">>>   2021/08/09 23:09:34 Successfully logged into the docker registry.\n",
      ">>>   2021/08/09 23:09:34 Start run pull docker image command\n",
      ">>>   2021/08/09 23:09:35 Pull docker image succeeded.\n",
      ">>>   2021/08/09 23:09:35 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/docker_login_7FAF328B0632D63B\n",
      ">>>   2021/08/09 23:09:35 Pull docker image time: 649.754348ms\n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:35 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:35 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/09 23:09:35 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/09 23:09:35 Setting the memory limit for docker container to be 55987 MB\n",
      ">>>   2021/08/09 23:09:35 The env variable file size is 43739 bytes\n",
      ">>>   2021/08/09 23:09:35 Creating parent cgroup '87808ff9-f9b8-4808-b68c-a9a848478c4e' for Containers used in Job\n",
      ">>>   2021/08/09 23:09:35 Add parent cgroup '87808ff9-f9b8-4808-b68c-a9a848478c4e' to container '87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar'\n",
      ">>>   2021/08/09 23:09:35 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/08/09 23:09:35 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,--gpus,all,-m,55987m,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.batchai.envlist,--cgroup-parent=/87808ff9-f9b8-4808-b68c-a9a848478c4e/,--shm-size,2g,-v,/:/mnt/hostfs:rshared,--env,SIDECAR_HOSTFS=/mnt/hostfs,--env,SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e,--env,AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.batchai.envlist,--env,AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true\n",
      ">>>   2021/08/09 23:09:35 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/08/09 23:09:35 the binding /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e \n",
      ">>>   2021/08/09 23:09:35 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar,--gpus,all,-m,55987m,-w,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.batchai.envlist,--cgroup-parent=/87808ff9-f9b8-4808-b68c-a9a848478c4e/,--shm-size,2g,--env,SIDECAR_HOSTFS=/mnt/hostfs,--env,SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e,--env,AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.batchai.envlist,--env,AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true,-v,/:/mnt/hostfs:rshared,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs\n",
      ">>>   2021/08/09 23:09:35 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar --gpus all -m 55987m -w /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.batchai.envlist --cgroup-parent=/87808ff9-f9b8-4808-b68c-a9a848478c4e/ --shm-size 2g --env SIDECAR_HOSTFS=/mnt/hostfs --env SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e --env AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.batchai.envlist --env AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true -v /:/mnt/hostfs:rshared -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e -v /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd -v /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs -d -it --privileged --net=host viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a\n",
      ">>>   2021/08/09 23:09:35 Check if container 87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:35 Check if container 87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:35 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/09 23:09:35 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/09 23:09:35 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-e16fe67547554bc85a1680e5b70637b1-12fc2ddffc9e562f-01 -sshRequired=false] \n",
      ">>>   2021/08/09 23:09:35 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-e16fe67547554bc85a1680e5b70637b1-12fc2ddffc9e562f-01 -sshRequired=false] \n",
      ">>>   2021/08/09 23:09:36 Container ssh is not required for job type.\n",
      ">>>   2021/08/09 23:09:36 Starting docker container succeeded.\n",
      ">>>   2021/08/09 23:09:36 Starting docker container succeeded.\n",
      ">>>   2021/08/09 23:09:36 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:36 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/09 23:09:36 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/09 23:09:36 Waiting for sidecar container 87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar to start running.\n",
      ">>>   2021/08/09 23:09:36 Running command /usr/bin/docker inspect -f {{.State.Running}} 87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar\n",
      ">>>   2021/08/09 23:09:36 Waiting for sidecar container to be ready.\n",
      ">>>   2021/08/09 23:09:36 Running command /usr/bin/docker exec 87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar sh -c python -c 'from azureml.sidecar.ipc import IPC_FILE;import os;print(\"IsSidecarReady:{}\".format(os.path.exists(IPC_FILE)))'\n",
      ">>>   2021/08/09 23:09:37 Sidecar container is running and TaskServer is ready.\n",
      ">>>   2021/08/09 23:09:37 Run job preparation command in Sidecar container\n",
      ">>>   2021/08/09 23:09:37 runSpecialJobTask: checking control script content under dir: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e-setup\n",
      ">>>   2021/08/09 23:09:38 runSpecialJobTask: control script dir content: [_tracer.py: size=2022 md5=4c1dd974ef27d1cbec1434a93802ac73; _tracing.py: size=26407 md5=64b473943a5d2905628a9b2097f18081; _vendor_jwt_decode.py: size=2277 md5=d4b49e48ed904f03a4d6ad2f64f17368; azureml_globals.py: size=12242 md5=3700b728b132e633c956f368d13818e4; context_managers.py: size=48073 md5=1d499aa329dc1debda235d60098e98dd; job_prep.py: size=11214 md5=13bb64f32d440c1fbaff3644045668fc; log_history_status.py: size=4428 md5=778bbe2bb6cb72340d4344366f752a63; request_utilities.py: size=1185 md5=e053daf561ffebe1c54811d9dc11beaa; run_token_provider.py: size=4228 md5=b167c8697df9c999e3676723caa93cb3; utility_context_managers.py: size=5015 md5=824d969dee21cf92733986c744d17142]\n",
      ">>>   2021/08/09 23:09:38 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs\n",
      ">>>   2021/08/09 23:09:38 runSpecialJobTask: Raw cmd for preparation is passed is: python /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8675f058-2d6d-4f4e-a69b-b2c31232dd94\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/09 23:09:38 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:09:38 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:09:38 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e;python /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8675f058-2d6d-4f4e-a69b-b2c31232dd94\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/09 23:09:38 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/08/09 23:09:38 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-e16fe67547554bc85a1680e5b70637b1-fc9549bcb75831fa-01 -t 87808ff9-f9b8-4808-b68c-a9a848478c4e_DataSidecar bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e;python /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/workspaceblobstore/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8675f058-2d6d-4f4e-a69b-b2c31232dd94\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/09 23:09:38 Attempt 1 of http call to https://westeurope.api.azureml.ms/history/v1.0/private/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourceGroups/lis/providers/Microsoft.MachineLearningServices/workspaces/lis-ml/runs/87808ff9-f9b8-4808-b68c-a9a848478c4e/spans\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.281905] Entering job preparation.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.918072] Starting job preparation.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.918107] Extracting the control code.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.918588] Starting extract_project.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.918632] Starting to extract zip file.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.974812] Finished extracting zip file.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.977867] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.977912] Start fetching snapshots.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.977944] Start fetching snapshot.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:38.977959] Retrieving project from snapshot: 8675f058-2d6d-4f4e-a69b-b2c31232dd94\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 54\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.569219] Finished fetching snapshot.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.569264] Finished fetching snapshots.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.569278] Finished extract_project.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.569336] Finished fetching and extracting the control code.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.575214] Start run_history_prep.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.581810] Job preparation is complete.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.581933] Entering Data Context Managers in Sidecar\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.582571] Running Sidecar prep cmd...\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.967520] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:39.968216] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: Enter __enter__ of DatasetContextManager\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: SDK version: azureml-core==1.32.0 azureml-dataprep==2.20.1. Session id: 5447b610-9a05-4262-bf72-330bcf75ea3e. Run id: 87808ff9-f9b8-4808-b68c-a9a848478c4e.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [[[Context Manager output has been redacted.]]]\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:46.920641] Ran Sidecar prep cmd.\n",
      ">>>   2021/08/09 23:09:47 runSpecialJobTask: preparation: [2021-08-09T23:09:46.920730] Running Context Managers in Sidecar complete.\n",
      ">>>   2021/08/09 23:09:47 Job preparation command in Sidecar container completed\n",
      ">>>   2021/08/09 23:09:47 Sidecar setup completed\n",
      ">>>   2021/08/09 23:09:47 Start to pulling docker image: 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      ">>>   2021/08/09 23:09:47 Start pull docker image: 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io\n",
      ">>>   2021/08/09 23:09:47 Getting credentials for image 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff with url 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io\n",
      ">>>   2021/08/09 23:09:47 Container registry is ACR.\n",
      ">>>   2021/08/09 23:09:47 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/08/09 23:09:47 Getting ACR Credentials from EMS for environment pipeline-env:Autosave_2021-08-09T13:40:51Z_738b2e1a\n",
      ">>>   2021/08/09 23:09:47 Requesting XDS for registry details.\n",
      ">>>   2021/08/09 23:09:47 Attempt 1 of http call to https://westeurope-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourceGroups/lis/workspaces/lis-ml/clusters/pipeline-cluster/nodes/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d?api-version=2018-02-01\n",
      ">>>   2021/08/09 23:09:47 Got container registry details from credentials service for registry address: 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io.\n",
      ">>>   2021/08/09 23:09:47 Writing ACR Details to file...\n",
      ">>>   2021/08/09 23:09:47 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/08/09 23:09:47 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/08/09 23:09:47 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/08/09 23:09:47 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/08/09 23:09:47 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/08/09 23:09:47 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/08/09 23:09:47 EMS returned 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io for environment pipeline-env\n",
      ">>>   2021/08/09 23:09:47 Save docker credentials for image 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff in /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/docker_login_7C5C558D14C518E1\n",
      ">>>   2021/08/09 23:09:47 Start login to the docker registry\n",
      ">>>   2021/08/09 23:09:47 Successfully logged into the docker registry.\n",
      ">>>   2021/08/09 23:09:47 Start run pull docker image command\n",
      ">>>   2021/08/09 23:09:47 Pull docker image succeeded.\n",
      ">>>   2021/08/09 23:09:47 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/docker_login_7C5C558D14C518E1\n",
      ">>>   2021/08/09 23:09:47 Pull docker image time: 410.298483ms\n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:47 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:47 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/09 23:09:47 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/09 23:09:47 Setting the memory limit for docker container to be 55987 MB\n",
      ">>>   2021/08/09 23:09:47 The env variable file size is 44505 bytes\n",
      ">>>   2021/08/09 23:09:47 Add parent cgroup '87808ff9-f9b8-4808-b68c-a9a848478c4e' to container '87808ff9-f9b8-4808-b68c-a9a848478c4e'\n",
      ">>>   2021/08/09 23:09:47 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/08/09 23:09:47 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,87808ff9-f9b8-4808-b68c-a9a848478c4e,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,--gpus,all,-m,55987m,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.batchai.envlist,--cgroup-parent=/87808ff9-f9b8-4808-b68c-a9a848478c4e/,--shm-size,2g,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/output_datastore_path_lis_artifacts:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/output_datastore_path_lis_artifacts:rslave,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/tmpej5emswd:/tmp/b5cc3e6e-d856-4981-af23-360039777fb9/e2a107b2-5d5f-490b-817f-edb3476e61fe:rslave,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/tmplc2hligs:/tmp/6153f067-ff23-4066-b155-c7372aee6868/c8f6bf68-8894-434b-8bec-ee131711bbd7:rslave\n",
      ">>>   2021/08/09 23:09:47 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/08/09 23:09:47 the binding /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e \n",
      ">>>   2021/08/09 23:09:47 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,87808ff9-f9b8-4808-b68c-a9a848478c4e,--gpus,all,-m,55987m,-w,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.batchai.envlist,--cgroup-parent=/87808ff9-f9b8-4808-b68c-a9a848478c4e/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/tmplc2hligs:/tmp/6153f067-ff23-4066-b155-c7372aee6868/c8f6bf68-8894-434b-8bec-ee131711bbd7:rslave,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/tmpej5emswd:/tmp/b5cc3e6e-d856-4981-af23-360039777fb9/e2a107b2-5d5f-490b-817f-edb3476e61fe:rslave,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/output_datastore_path_lis_artifacts:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/output_datastore_path_lis_artifacts:rslave,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs\n",
      ">>>   2021/08/09 23:09:47 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 87808ff9-f9b8-4808-b68c-a9a848478c4e --gpus all -m 55987m -w /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/config/.batchai.envlist --cgroup-parent=/87808ff9-f9b8-4808-b68c-a9a848478c4e/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e -v /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/tmplc2hligs:/tmp/6153f067-ff23-4066-b155-c7372aee6868/c8f6bf68-8894-434b-8bec-ee131711bbd7:rslave -v /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/tmpej5emswd:/tmp/b5cc3e6e-d856-4981-af23-360039777fb9/e2a107b2-5d5f-490b-817f-edb3476e61fe:rslave -v /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/output_datastore_path_lis_artifacts:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/output_datastore_path_lis_artifacts:rslave -v /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/wd -v /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/87808ff9-f9b8-4808-b_1081bcdc-a826-4ed3-9c3b-e9ed72f63112/certs -d -it --privileged --net=host 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      ">>>   2021/08/09 23:09:47 Check if container 87808ff9-f9b8-4808-b68c-a9a848478c4e already exist exited with 0, 414399043f16\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:47 Check if container 87808ff9-f9b8-4808-b68c-a9a848478c4e already exist exited with 0, 414399043f16\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:47 The container 87808ff9-f9b8-4808-b68c-a9a848478c4e already exists, stop and remove it before starting it.\n",
      ">>>   2021/08/09 23:09:47 The container 87808ff9-f9b8-4808-b68c-a9a848478c4e already exists, stop and remove it before starting it.\n",
      ">>>   2021/08/09 23:09:47 Stopping container 87808ff9-f9b8-4808-b68c-a9a848478c4e exited with 1, Error response from daemon: No such container: 87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:47 Stopping container 87808ff9-f9b8-4808-b68c-a9a848478c4e exited with 1, Error response from daemon: No such container: 87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:47 Removing container 87808ff9-f9b8-4808-b68c-a9a848478c4e exited with 1, Error: No such container: 87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:47 Removing container 87808ff9-f9b8-4808-b68c-a9a848478c4e exited with 1, Error: No such container: 87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      ">>>   \n",
      ">>>   \n",
      ">>>   2021/08/09 23:09:48 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/09 23:09:48 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/09 23:09:48 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-e16fe67547554bc85a1680e5b70637b1-b53dac55099e6448-01 -sshRequired=false] \n",
      ">>>   2021/08/09 23:09:48 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-e16fe67547554bc85a1680e5b70637b1-b53dac55099e6448-01 -sshRequired=false] \n",
      ">>>   2021/08/09 23:09:48 Attempt 1 of http call to https://westeurope.api.azureml.ms/history/v1.0/private/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourceGroups/lis/providers/Microsoft.MachineLearningServices/workspaces/lis-ml/runs/87808ff9-f9b8-4808-b68c-a9a848478c4e/spans\n",
      ">>>   2021/08/09 23:09:48 Container ssh is not required for job type.\n",
      ">>>   2021/08/09 23:09:48 Starting docker container succeeded.\n",
      ">>>   2021/08/09 23:09:48 Starting docker container succeeded.\n",
      ">>>   2021/08/09 23:09:48 Disk space after starting docker container: 319572MB\n",
      ">>>   2021/08/09 23:09:48 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 2\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/08/09 23:09:48 Process Exiting with Code:  0\n",
      ">>>   2021/08/09 23:09:49 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      ">>>   \n",
      "2021-08-09T23:09:49Z 127.0.0.1 slots=1 max-slots=1\n",
      "2021-08-09T23:09:49Z launching Custom job\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/08/09 23:09:49 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/08/09 23:09:49 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/09 23:09:49 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/08/09 23:09:49 Send process info logs to master server succeeded\n",
      "2021/08/09 23:09:49 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/09 23:09:49 Send process info logs to master server succeeded\n",
      "[2021-08-09T23:09:49.284292] Entering context manager injector.\n",
      "[2021-08-09T23:09:49.780755] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['lis_components/train/train.py', '--model_name', 'gpt2', '--output_dir', 'DatasetOutputConfig:output_datastore_path', '--train_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts/data/train.csv', '--eval_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts/data/eval.csv', '--num_train_epochs', '1', '--max_train_samples', '8', '--max_eval_samples', '8'])\n",
      "Script type = None\n",
      "[2021-08-09T23:09:49.784693] Entering Run History Context Manager.\n",
      "[2021-08-09T23:09:50.465975] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      "[2021-08-09T23:09:50.466241] Preparing to call script [lis_components/train/train.py] with arguments:['--model_name', 'gpt2', '--output_dir', '$output_datastore_path', '--train_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts/data/train.csv', '--eval_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts/data/eval.csv', '--num_train_epochs', '1', '--max_train_samples', '8', '--max_eval_samples', '8']\n",
      "[2021-08-09T23:09:50.466328] After variable expansion, calling script [lis_components/train/train.py] with arguments:['--model_name', 'gpt2', '--output_dir', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/output_datastore_path_lis_artifacts', '--train_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts/data/train.csv', '--eval_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/mounts/lis_artifacts/data/eval.csv', '--num_train_epochs', '1', '--max_train_samples', '8', '--max_eval_samples', '8']\n",
      "\n",
      "2021-08-09 23:09:50.630759: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:09:50.630794: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Using custom data configuration default-87215c42f45737ca\n",
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-87215c42f45737ca/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n",
      "\n",
      "0 tables [00:00, ? tables/s]\n",
      "                            \n",
      "\n",
      "0 tables [00:00, ? tables/s]\n",
      "                            \n",
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-87215c42f45737ca/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n",
      "\n",
      "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]\n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 650kB/s]\n",
      "2021/08/09 23:09:54 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]\n",
      "Downloading:  17%|█▋        | 176k/1.04M [00:00<00:00, 932kB/s]\n",
      "Downloading:  75%|███████▌  | 784k/1.04M [00:00<00:00, 3.15MB/s]\n",
      "Downloading: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.74MB/s]\n",
      "\n",
      "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]\n",
      "Downloading:  39%|███▊      | 176k/456k [00:00<00:00, 930kB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 2.34MB/s]\n",
      "\n",
      "Adding eos_token to each example in the dataset:   0%|          | 0/11 [00:00<?, ?ba/s]\n",
      "Adding eos_token to each example in the dataset: 100%|██████████| 11/11 [00:00<00:00, 473.56ba/s]\n",
      "\n",
      "Adding eos_token to each example in the dataset:   0%|          | 0/4 [00:00<?, ?ba/s]\n",
      "Adding eos_token to each example in the dataset: 100%|██████████| 4/4 [00:00<00:00, 504.81ba/s]\n",
      "\n",
      "Running tokenizer on dataset:   0%|          | 0/11 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:   9%|▉         | 1/11 [00:00<00:01,  6.13ba/s]\n",
      "Running tokenizer on dataset:  18%|█▊        | 2/11 [00:00<00:01,  6.72ba/s]\n",
      "Running tokenizer on dataset:  27%|██▋       | 3/11 [00:00<00:01,  6.66ba/s]\n",
      "Running tokenizer on dataset:  36%|███▋      | 4/11 [00:00<00:01,  6.85ba/s]\n",
      "Running tokenizer on dataset:  45%|████▌     | 5/11 [00:00<00:00,  7.04ba/s]\n",
      "Running tokenizer on dataset:  55%|█████▍    | 6/11 [00:00<00:00,  6.84ba/s]\n",
      "Running tokenizer on dataset:  64%|██████▎   | 7/11 [00:01<00:00,  6.96ba/s]\n",
      "Running tokenizer on dataset:  73%|███████▎  | 8/11 [00:01<00:00,  7.00ba/s]\n",
      "Running tokenizer on dataset:  82%|████████▏ | 9/11 [00:01<00:00,  7.05ba/s]\n",
      "Running tokenizer on dataset:  91%|█████████ | 10/11 [00:01<00:00,  7.31ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 11/11 [00:01<00:00,  7.70ba/s]\n",
      "\n",
      "Running tokenizer on dataset:   0%|          | 0/4 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:  25%|██▌       | 1/4 [00:00<00:00,  7.45ba/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 2/4 [00:00<00:00,  6.94ba/s]\n",
      "Running tokenizer on dataset:  75%|███████▌  | 3/4 [00:00<00:00,  7.31ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 4/4 [00:00<00:00,  9.46ba/s]\n",
      "\n",
      "Grouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|██████████| 1/1 [00:06<00:00,  6.69s/ba]\n",
      "Grouping texts in chunks of 1024: 100%|██████████| 1/1 [00:06<00:00,  6.69s/ba]\n",
      "\n",
      "Grouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|██████████| 1/1 [00:00<00:00,  1.63ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|██████████| 1/1 [00:00<00:00,  1.63ba/s]\n",
      "2021-08-09 23:10:10.437600: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-09 23:10:10.474661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0cb7:00:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-08-09 23:10:10.474824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:10:10.474950: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:10:10.475072: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:10:10.475183: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:10:10.475300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:10:10.475409: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:10:10.475513: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:10:10.475617: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:10:10.475634: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-08-09 23:10:10.476117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-09 23:10:10.476509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-09 23:10:10.476525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "\n",
      "Downloading:   0%|          | 0.00/498M [00:00<?, ?B/s]\n",
      "Downloading:   1%|          | 5.16M/498M [00:00<00:09, 51.6MB/s]\n",
      "Downloading:   2%|▏         | 10.9M/498M [00:00<00:08, 54.7MB/s]\n",
      "Downloading:   3%|▎         | 17.0M/498M [00:00<00:08, 57.7MB/s]\n",
      "Downloading:   5%|▍         | 23.5M/498M [00:00<00:07, 60.5MB/s]\n",
      "Downloading:   6%|▌         | 30.0M/498M [00:00<00:07, 62.3MB/s]\n",
      "Downloading:   7%|▋         | 36.5M/498M [00:00<00:07, 63.2MB/s]\n",
      "Downloading:   9%|▊         | 43.2M/498M [00:00<00:07, 64.4MB/s]\n",
      "Downloading:  10%|█         | 50.0M/498M [00:00<00:06, 65.5MB/s]\n",
      "Downloading:  11%|█▏        | 56.7M/498M [00:00<00:06, 66.1MB/s]\n",
      "Downloading:  13%|█▎        | 63.5M/498M [00:01<00:06, 66.7MB/s]\n",
      "Downloading:  14%|█▍        | 70.2M/498M [00:01<00:06, 66.8MB/s]\n",
      "Downloading:  15%|█▌        | 76.9M/498M [00:01<00:06, 66.9MB/s]\n",
      "Downloading:  17%|█▋        | 83.7M/498M [00:01<00:06, 67.0MB/s]\n",
      "Downloading:  18%|█▊        | 90.4M/498M [00:01<00:06, 67.3MB/s]\n",
      "Downloading:  20%|█▉        | 97.2M/498M [00:01<00:05, 67.2MB/s]\n",
      "Downloading:  21%|██        | 104M/498M [00:01<00:05, 67.3MB/s] \n",
      "Downloading:  22%|██▏       | 111M/498M [00:01<00:05, 67.2MB/s]\n",
      "Downloading:  24%|██▎       | 117M/498M [00:01<00:05, 67.3MB/s]\n",
      "Downloading:  25%|██▍       | 124M/498M [00:01<00:05, 67.5MB/s]\n",
      "Downloading:  26%|██▋       | 131M/498M [00:02<00:05, 67.6MB/s]\n",
      "Downloading:  28%|██▊       | 138M/498M [00:02<00:05, 67.5MB/s]\n",
      "Downloading:  29%|██▉       | 145M/498M [00:02<00:05, 67.6MB/s]\n",
      "Downloading:  30%|███       | 151M/498M [00:02<00:05, 67.7MB/s]\n",
      "Downloading:  32%|███▏      | 158M/498M [00:02<00:05, 66.3MB/s]\n",
      "Downloading:  33%|███▎      | 165M/498M [00:02<00:05, 66.5MB/s]\n",
      "Downloading:  34%|███▍      | 172M/498M [00:02<00:04, 66.9MB/s]\n",
      "Downloading:  36%|███▌      | 178M/498M [00:02<00:04, 67.0MB/s]\n",
      "Downloading:  37%|███▋      | 185M/498M [00:02<00:04, 67.2MB/s]\n",
      "Downloading:  39%|███▊      | 192M/498M [00:02<00:04, 67.3MB/s]\n",
      "Downloading:  40%|███▉      | 199M/498M [00:03<00:04, 67.4MB/s]\n",
      "Downloading:  41%|████▏     | 205M/498M [00:03<00:04, 67.6MB/s]\n",
      "Downloading:  43%|████▎     | 212M/498M [00:03<00:04, 67.6MB/s]\n",
      "Downloading:  44%|████▍     | 219M/498M [00:03<00:04, 67.5MB/s]\n",
      "Downloading:  45%|████▌     | 226M/498M [00:03<00:04, 67.6MB/s]\n",
      "Downloading:  47%|████▋     | 232M/498M [00:03<00:03, 67.2MB/s]\n",
      "Downloading:  48%|████▊     | 239M/498M [00:03<00:03, 67.2MB/s]\n",
      "Downloading:  49%|████▉     | 246M/498M [00:03<00:03, 67.4MB/s]\n",
      "Downloading:  51%|█████     | 253M/498M [00:03<00:03, 67.3MB/s]\n",
      "Downloading:  52%|█████▏    | 260M/498M [00:03<00:03, 67.5MB/s]\n",
      "Downloading:  53%|█████▎    | 266M/498M [00:04<00:03, 67.1MB/s]\n",
      "Downloading:  55%|█████▍    | 273M/498M [00:04<00:03, 66.3MB/s]\n",
      "Downloading:  56%|█████▌    | 280M/498M [00:04<00:03, 66.2MB/s]\n",
      "Downloading:  57%|█████▋    | 286M/498M [00:04<00:03, 65.8MB/s]\n",
      "Downloading:  59%|█████▉    | 293M/498M [00:04<00:03, 65.6MB/s]\n",
      "Downloading:  60%|██████    | 299M/498M [00:04<00:03, 65.2MB/s]\n",
      "Downloading:  61%|██████▏   | 306M/498M [00:04<00:02, 65.2MB/s]\n",
      "Downloading:  63%|██████▎   | 312M/498M [00:04<00:02, 64.8MB/s]\n",
      "Downloading:  64%|██████▍   | 319M/498M [00:04<00:02, 65.6MB/s]\n",
      "Downloading:  65%|██████▌   | 326M/498M [00:04<00:02, 66.1MB/s]\n",
      "Downloading:  67%|██████▋   | 333M/498M [00:05<00:02, 66.6MB/s]\n",
      "Downloading:  68%|██████▊   | 339M/498M [00:05<00:02, 66.7MB/s]\n",
      "Downloading:  70%|██████▉   | 346M/498M [00:05<00:02, 67.2MB/s]\n",
      "Downloading:  71%|███████   | 353M/498M [00:05<00:02, 67.1MB/s]\n",
      "Downloading:  72%|███████▏  | 360M/498M [00:05<00:02, 67.3MB/s]\n",
      "Downloading:  74%|███████▎  | 366M/498M [00:05<00:01, 67.3MB/s]\n",
      "Downloading:  75%|███████▍  | 373M/498M [00:05<00:01, 67.2MB/s]\n",
      "Downloading:  76%|███████▋  | 380M/498M [00:05<00:01, 67.2MB/s]\n",
      "Downloading:  78%|███████▊  | 387M/498M [00:05<00:01, 67.5MB/s]\n",
      "Downloading:  79%|███████▉  | 393M/498M [00:05<00:01, 67.0MB/s]\n",
      "Downloading:  80%|████████  | 400M/498M [00:06<00:01, 66.6MB/s]\n",
      "Downloading:  82%|████████▏ | 407M/498M [00:06<00:01, 64.0MB/s]\n",
      "Downloading:  83%|████████▎ | 413M/498M [00:06<00:01, 64.0MB/s]\n",
      "Downloading:  84%|████████▍ | 420M/498M [00:06<00:01, 64.4MB/s]\n",
      "Downloading:  86%|████████▌ | 426M/498M [00:06<00:01, 64.6MB/s]\n",
      "Downloading:  87%|████████▋ | 433M/498M [00:06<00:01, 63.7MB/s]\n",
      "Downloading:  88%|████████▊ | 439M/498M [00:06<00:00, 63.6MB/s]\n",
      "Downloading:  89%|████████▉ | 446M/498M [00:06<00:00, 63.9MB/s]\n",
      "Downloading:  91%|█████████ | 452M/498M [00:06<00:00, 64.0MB/s]\n",
      "Downloading:  92%|█████████▏| 458M/498M [00:06<00:00, 64.1MB/s]\n",
      "Downloading:  93%|█████████▎| 465M/498M [00:07<00:00, 64.2MB/s]\n",
      "Downloading:  95%|█████████▍| 471M/498M [00:07<00:00, 64.1MB/s]\n",
      "Downloading:  96%|█████████▌| 478M/498M [00:07<00:00, 62.9MB/s]\n",
      "Downloading:  97%|█████████▋| 484M/498M [00:07<00:00, 61.7MB/s]\n",
      "Downloading:  98%|█████████▊| 490M/498M [00:07<00:00, 62.2MB/s]\n",
      "Downloading: 100%|█████████▉| 497M/498M [00:07<00:00, 63.1MB/s]\n",
      "Downloading: 100%|██████████| 498M/498M [00:07<00:00, 65.7MB/s]\n",
      "2021-08-09 23:10:18.957384: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "2021-08-09 23:10:20.907586: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-09 23:10:20.908009: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2596985000 Hz\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3749 - output_1_loss: 3.3749\n",
      "1/1 [==============================] - 63s 63s/step - loss: 3.3749 - output_1_loss: 3.3749 - val_loss: 2.7897 - val_output_1_loss: 2.7897\n",
      "[2021-08-09T23:12:16.163094] Reloading <module '__main__' from 'lis_components/train/train.py'> failed: module __main__ not in sys.modules.\n",
      "\n",
      "\n",
      "[2021-08-09T23:12:16.163439] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.23900437355041504 seconds\n",
      "[2021-08-09T23:12:16.570977] Finished context manager injector.\n",
      "2021/08/09 23:12:18 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/09 23:12:18 Send process info logs to master server succeeded\n",
      "2021/08/09 23:12:18 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 2\n",
      "FilteredData: 0.\n",
      "2021/08/09 23:12:18 Process Exiting with Code:  0\n",
      "2021/08/09 23:12:18 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "===============================================================================================================\n",
      "[2021-08-09T23:12:19.687923] Entering job release\n",
      "[2021-08-09T23:12:20.463361] Starting job release\n",
      "[2021-08-09T23:12:20.463751] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 340\n",
      "[2021-08-09T23:12:20.464498] job release stage : upload_datastore starting...[2021-08-09T23:12:20.464736] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-08-09T23:12:20.466703] job release stage : copy_batchai_cached_logs starting...\n",
      "\n",
      "[2021-08-09T23:12:20.466964] job release stage : execute_job_release starting...[2021-08-09T23:12:20.467003] job release stage : copy_batchai_cached_logs completed...\n",
      "\n",
      "[2021-08-09T23:12:20.477700] Entering context manager injector.\n",
      "[2021-08-09T23:12:20.498295] job release stage : upload_datastore completed...\n",
      "[2021-08-09T23:12:20.601427] job release stage : send_run_telemetry starting...\n",
      "[2021-08-09T23:12:20.614934] get vm size and vm region successfully.\n",
      "[2021-08-09T23:12:20.621992] get compute meta data successfully.\n",
      "[2021-08-09T23:12:20.710055] job release stage : execute_job_release completed...\n",
      "[2021-08-09T23:12:20.837867] post artifact meta request successfully.\n",
      "[2021-08-09T23:12:20.867952] upload compute record artifact successfully.\n",
      "[2021-08-09T23:12:20.868010] job release stage : send_run_telemetry completed...\n",
      "[2021-08-09T23:12:20.868342] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-08-09T23:12:20.868448] Running Sidecar release cmd...\n",
      "[2021-08-09T23:12:20.879324] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/output_datastore_path_lis_artifacts.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/87808ff9-f9b8-4808-b68c-a9a848478c4e/wd/output_datastore_path_lis_artifacts.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-08-09T23:12:20.988972] Removing absolute paths from host...\n",
      "[2021-08-09T23:12:20.989201] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-08-09T23:12:21.507061] Ran Sidecar release cmd.\n",
      "[2021-08-09T23:12:21.507147] Job release is complete\n",
      "\n",
      "StepRun(Train) Execution Summary\n",
      "=================================\n",
      "StepRun( Train ) Status: Finished\n",
      "{'runId': '87808ff9-f9b8-4808-b68c-a9a848478c4e', 'target': 'pipeline-cluster', 'status': 'Completed', 'startTimeUtc': '2021-08-09T23:09:32.630791Z', 'endTimeUtc': '2021-08-09T23:12:28.749045Z', 'properties': {'ContentSnapshotId': '8675f058-2d6d-4f4e-a69b-b2c31232dd94', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '9d96330e-3873-4610-83b7-957b4016babf', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '17b50458', 'azureml.pipelinerunid': 'f29233bb-ae00-4b8c-bf50-7e1cd833cd29', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.RuntimeType': 'Hosttools'}, 'inputDatasets': [], 'outputDatasets': [{'identifier': {'savedId': '6c598996-ab02-4468-ad73-9acfbe6572cf'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'output_datastore_path'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('lis_artifacts', 'outputs')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"6c598996-ab02-4468-ad73-9acfbe6572cf\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='lis-ml', subscription_id='2f091423-f84d-4062-8e67-1437a0c50045', resource_group='lis')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'lis_components/train/train.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', 'gpt2', '--output_dir', 'DatasetOutputConfig:output_datastore_path', '--train_file', '$AZUREML_DATAREFERENCE_train_datastore_path', '--eval_file', '$AZUREML_DATAREFERENCE_eval_datastore_path', '--num_train_epochs', '$AML_PARAMETER_num_train_epochs', '--max_train_samples', '8', '--max_eval_samples', '8'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'pipeline-cluster', 'dataReferences': {'train_datastore_path': {'dataStoreName': 'lis_artifacts', 'mode': 'Mount', 'pathOnDataStore': 'data/train.csv', 'pathOnCompute': None, 'overwrite': False}, 'eval_datastore_path': {'dataStoreName': 'lis_artifacts', 'mode': 'Mount', 'pathOnDataStore': 'data/eval.csv', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {'output_datastore_path': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'lis_artifacts', 'relativePath': 'outputs'}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'pipeline-env', 'version': 'Autosave_2021-08-09T13:40:51Z_738b2e1a', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.9', 'pip', {'pip': ['transformers == 3.5.1', 'datasets == 1.10.2', 'tensorflow == 2.5.0', 'azureml-defaults==1.30.0']}], 'name': 'azureml_82f5617ca19cd57b18cafd61c017ea7a'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210531.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': 'westus2', 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard'}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_num_train_epochs': '1'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=KnXrlLRNdv%2FQLyOff4S2HgJdx3GjCnaJY8xKCWAT8dY%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=4nBKa0ypOBQV%2BR7CM8WUO658BNzvFFsi6zRrvOLVfPo%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=HU79kpvATkbiUbG9mvtHE2viW0VR7f4HG8gV1bndzNI%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=3%2FAy5E5IF45hzCSvAB5%2FBg5QGXwN2DbpT2v5A0Ao%2BVo%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'azureml-logs/process_info.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=LE7Zz6ZeRKt%2BKzvMwi2CaXNOUhbYi5%2BHclYKkBSdPZU%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'azureml-logs/process_status.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=M61kA3Ciyujc4tXZ%2FM7IgYkYw1ZZTLk6HIVRe0ev2v8%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/74_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/74_azureml.log?sv=2019-07-07&sr=b&sig=75ioE1GKYnOGZdZ9e2ias5oQxci%2BxNU1PHOpL7bMzVw%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=HtjNxkl89qKGzccK8O6lD1PNasu4R5i3w0haupIRtYY%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=a5oxqcSWo03ScgQyPPwy5hu7%2F2w17JWg1fy1sC89a5s%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=R2FeQYIsOLaYwrybE74mLof21ozO1pxavx1y1IevzAc%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=QV4CqwOKDR9W5UgtAGhfnwSG8ECu%2BHdc44oQ3%2F2v590%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=bs%2FHbp1ZwQ3hAgHv06ucz7e%2Fm53QdD2%2Fn6OSQTxXmBI%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/all.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/all.log?sv=2019-07-07&sr=b&sig=15pzbVtURfyv7BI%2FopDU5AXNC9%2Fn0fzyO6u%2B1aJE4Tw%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.enter_contexts.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=iFpw4pvEdX4XzPil68GFK3%2B86BwQbMkQ85lVex0fX3c%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.exit_contexts.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=9Hdx9bSGjlRw9J1nVzkPYYKoFRhNXkSyLLclKe6h5YE%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ZHsbDdCloMMOpBiLTcXJ6ScujIQkXLcBXyZFjsswW08%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.87808ff9-f9b8-4808-b68c-a9a848478c4e/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=nW0hf%2FuAVlnpOJpugRZakc51iQxRUHO7ZOJjF0M8Y34%3D&st=2021-08-09T23%3A02%3A23Z&se=2021-08-10T07%3A12%3A23Z&sp=r'}, 'submittedBy': 'Maggie Mhanna'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: 3e536e68-3c50-47bc-b0cd-64571614fbe9\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/3e536e68-3c50-47bc-b0cd-64571614fbe9?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Register ) Status: NotStarted\n",
      "StepRun( Register ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "========================================================================================================================\n",
      "2021-08-09T23:12:47Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-08-09T23:12:47Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/mounts/workspaceblobstore\n",
      "2021-08-09T23:12:47Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/mounts/lis_artifacts --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/caches/lis_artifacts --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/configs/lis_artifacts.cfg --log-level=LOG_WARNING\n",
      "2021-08-09T23:12:47Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/mounts/lis_artifacts\n",
      "2021-08-09T23:12:48Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-08-09T23:12:48Z Starting output-watcher...\n",
      "2021-08-09T23:12:48Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-08-09T23:12:48Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-09T23:12:48Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_5572ea249a896c3014db8569f38d4a1a\n",
      "Digest: sha256:e4fcde8761b0dca23a91150bd7745746e90d05fb0e676a7adfc7e6fce5b6ce18\n",
      "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a:latest\n",
      "2021-08-09T23:12:49Z Check if container 3e536e68-3c50-47bc-b0cd-64571614fbe9_DataSidecar already exist exited with 0, \n",
      "\n",
      "7c9b98758453a194bf0f543c22314d260f81c2f0462dc997efb6410ee8ed196c\n",
      "2021-08-09T23:12:49Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-09T23:12:49Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-57e374217b67a7f7a36add7760fe31e2-668199d34f897779-01 -sshRequired=false] \n",
      "2021/08/09 23:12:49 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/09 23:12:49 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/09 23:12:49 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/09 23:12:49 Starting infiniband setup\n",
      "2021/08/09 23:12:49 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/09 23:12:49 Returning Python Version as 3.7\n",
      "2021-08-09T23:12:49Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/09 23:12:49 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/09 23:12:49 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/09 23:12:49 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-08-09T23:12:49Z Not setting up Infiniband in Container\n",
      "2021/08/09 23:12:49 Not setting up Infiniband in Container\n",
      "2021/08/09 23:12:49 Not setting up Infiniband in Container\n",
      "2021/08/09 23:12:49 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/09 23:12:49 Returning Python Version as 3.7\n",
      "2021/08/09 23:12:49 sshd inside container not required for job, skipping setup.\n",
      "2021/08/09 23:12:50 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/09 23:12:50 App Insight Client has already been closed\n",
      "2021/08/09 23:12:50 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-09T23:12:50Z Starting docker container succeeded.\n",
      "2021-08-09T23:13:03Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-09T23:13:03Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/08/09 23:13:05 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/08/09 23:13:05 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/09 23:13:05 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/08/09 23:13:05 Send process info logs to master server succeeded\n",
      "2021/08/09 23:13:05 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/09 23:13:05 Send process info logs to master server succeeded\n",
      "[2021-08-09T23:13:05.263573] Entering context manager injector.\n",
      "[2021-08-09T23:13:05.764155] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['lis_components/register/register.py', '--model_name', 'lis-gpt2-model', '--model_dir', 'DatasetConsumptionConfig:input_0279e2c2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/mounts/lis_artifacts/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/register_deploy_link'])\n",
      "Script type = None\n",
      "[2021-08-09T23:13:05.768005] Entering Run History Context Manager.\n",
      "[2021-08-09T23:13:06.440275] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/wd/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9\n",
      "[2021-08-09T23:13:06.440505] Preparing to call script [lis_components/register/register.py] with arguments:['--model_name', 'lis-gpt2-model', '--model_dir', '$input_0279e2c2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/mounts/lis_artifacts/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/register_deploy_link']\n",
      "[2021-08-09T23:13:06.440548] After variable expansion, calling script [lis_components/register/register.py] with arguments:['--model_name', 'lis-gpt2-model', '--model_dir', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/wd/input_0279e2c2_6c598996-ab02-4468-ad73-9acfbe6572cf', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/mounts/lis_artifacts/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/register_deploy_link']\n",
      "\n",
      "Loading model from /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/wd/input_0279e2c2_6c598996-ab02-4468-ad73-9acfbe6572cf\n",
      "2021/08/09 23:13:10 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "\n",
      "[2021-08-09T23:13:20.345801] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "4 items cleaning up...\n",
      "Cleanup took 0.3151986598968506 seconds\n",
      "[2021-08-09T23:13:20.800807] Finished context manager injector.\n",
      "2021/08/09 23:13:21 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/09 23:13:21 Send process info logs to master server succeeded\n",
      "2021/08/09 23:13:21 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 2\n",
      "FilteredData: 0.\n",
      "2021/08/09 23:13:21 Process Exiting with Code:  0\n",
      "2021/08/09 23:13:22 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "===============================================================================================================\n",
      "[2021-08-09T23:13:22.810736] Entering job release\n",
      "[2021-08-09T23:13:23.602909] Starting job release\n",
      "[2021-08-09T23:13:23.603362] Logging experiment finalizing status in history service.\n",
      "[2021-08-09T23:13:23.603536] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 325\n",
      "\n",
      "[2021-08-09T23:13:23.603968] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-08-09T23:13:23.605978] job release stage : execute_job_release starting...[2021-08-09T23:13:23.606089] job release stage : copy_batchai_cached_logs starting...\n",
      "\n",
      "[2021-08-09T23:13:23.606480] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-08-09T23:13:23.616615] Entering context manager injector.\n",
      "[2021-08-09T23:13:23.635135] job release stage : upload_datastore completed...\n",
      "[2021-08-09T23:13:23.723890] job release stage : send_run_telemetry starting...\n",
      "[2021-08-09T23:13:23.742058] get vm size and vm region successfully.\n",
      "[2021-08-09T23:13:23.750211] get compute meta data successfully.\n",
      "[2021-08-09T23:13:23.825395] job release stage : execute_job_release completed...\n",
      "[2021-08-09T23:13:24.007520] post artifact meta request successfully.\n",
      "[2021-08-09T23:13:24.036400] upload compute record artifact successfully.\n",
      "[2021-08-09T23:13:24.036469] job release stage : send_run_telemetry completed...\n",
      "[2021-08-09T23:13:24.037084] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-08-09T23:13:24.037302] Running Sidecar release cmd...\n",
      "[2021-08-09T23:13:24.052224] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/wd/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/wd/input_0279e2c2_6c598996-ab02-4468-ad73-9acfbe6572cf.\n",
      "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/wd/input_0279e2c2_6c598996-ab02-4468-ad73-9acfbe6572cf: Invalid argument\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/wd/input_0279e2c2_6c598996-ab02-4468-ad73-9acfbe6572cf.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-08-09T23:13:24.108580] Removing absolute paths from host...\n",
      "[2021-08-09T23:13:24.108814] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-08-09T23:13:24.890229] Ran Sidecar release cmd.\n",
      "[2021-08-09T23:13:24.890316] Job release is complete\n",
      "\n",
      "StepRun(Register) Execution Summary\n",
      "====================================\n",
      "StepRun( Register ) Status: Finished\n",
      "{'runId': '3e536e68-3c50-47bc-b0cd-64571614fbe9', 'target': 'pipeline-cluster', 'status': 'Completed', 'startTimeUtc': '2021-08-09T23:12:46.041365Z', 'endTimeUtc': '2021-08-09T23:13:31.382784Z', 'properties': {'ContentSnapshotId': '8675f058-2d6d-4f4e-a69b-b2c31232dd94', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'ff9b1db8-f8bf-4c25-8b71-70de214e2b41', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'ab43254f', 'azureml.pipelinerunid': 'f29233bb-ae00-4b8c-bf50-7e1cd833cd29', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.RuntimeType': 'Hosttools'}, 'inputDatasets': [{'dataset': {'id': '6c598996-ab02-4468-ad73-9acfbe6572cf'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_0279e2c2', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'lis_components/register/register.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_aml_model_name', '--model_dir', 'DatasetConsumptionConfig:input_0279e2c2', '--register_deploy_link', '$AZUREML_DATAREFERENCE_register_deploy_link'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'pipeline-cluster', 'dataReferences': {'register_deploy_link': {'dataStoreName': 'lis_artifacts', 'mode': 'Mount', 'pathOnDataStore': 'azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/register_deploy_link', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'input_0279e2c2': {'dataLocation': {'dataset': {'id': '6c598996-ab02-4468-ad73-9acfbe6572cf', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_0279e2c2', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'pipeline-env', 'version': 'Autosave_2021-08-09T13:40:51Z_738b2e1a', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.9', 'pip', {'pip': ['transformers == 3.5.1', 'datasets == 1.10.2', 'tensorflow == 2.5.0', 'azureml-defaults==1.30.0']}], 'name': 'azureml_82f5617ca19cd57b18cafd61c017ea7a'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210531.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': 'westus2', 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard'}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_aml_model_name': 'lis-gpt2-model'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=D15oeM%2FuNwChFz6o%2FM2UPG0lLml9sDQ%2BuITa5mjcDBY%3D&st=2021-08-09T23%3A03%3A27Z&se=2021-08-10T07%3A13%3A27Z&sp=r', 'azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=GL1V4Pwit%2BWUwD4gADLT6sdon8DJ29kuxZNJbTZtm54%3D&st=2021-08-09T23%3A03%3A27Z&se=2021-08-10T07%3A13%3A27Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=MUN3z%2FZRR14rgSrHX8EclF91%2FXM%2FXWZXRokWDJyr3ys%3D&st=2021-08-09T23%3A03%3A27Z&se=2021-08-10T07%3A13%3A27Z&sp=r', 'azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=DG43cZ6rn6mTgfJgB5nHnjnj8NFh1WoF5UW4iK9LXzc%3D&st=2021-08-09T23%3A03%3A27Z&se=2021-08-10T07%3A13%3A27Z&sp=r', 'azureml-logs/process_info.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=Clk4%2FtDu2VAqP0j%2F2CwbRN3C289yjIy8SmAiOTciOZ0%3D&st=2021-08-09T23%3A03%3A27Z&se=2021-08-10T07%3A13%3A27Z&sp=r', 'azureml-logs/process_status.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=%2FGhPpIhgRLgqZpck%2F7Eg27ttw1%2BSgIQNHhPcGdBgJ0I%3D&st=2021-08-09T23%3A03%3A27Z&se=2021-08-10T07%3A13%3A27Z&sp=r', 'logs/azureml/80_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/80_azureml.log?sv=2019-07-07&sr=b&sig=5iGJBw5v%2BHCTPbOiBWoTX4fEc3xMdprTuMZNZk27M9g%3D&st=2021-08-09T23%3A03%3A25Z&se=2021-08-10T07%3A13%3A25Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=4x3654LjEbTIFI1Wyy7Uf%2B%2FA7JDFwncS9ZpwaDxVAPk%3D&st=2021-08-09T23%3A03%3A25Z&se=2021-08-10T07%3A13%3A25Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=u4teHQr1uJ6NCmV5KZr70%2F7bCxNoZyZ8asAPdnnU7gU%3D&st=2021-08-09T23%3A03%3A25Z&se=2021-08-10T07%3A13%3A25Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=YIeQVWfles2Fk%2BcjDFF%2FoQaFxMVb9p5Dv6MLjNA7EpY%3D&st=2021-08-09T23%3A03%3A25Z&se=2021-08-10T07%3A13%3A25Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=Ab5QZfcrxv6%2FhrKFV3kKGYo3JhfX1QXUsKmdgISvq6I%3D&st=2021-08-09T23%3A03%3A25Z&se=2021-08-10T07%3A13%3A25Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=up7J4WhBujxcH7zLNVJas4OCWU8DTSGsVsKOnjL8YCo%3D&st=2021-08-09T23%3A03%3A25Z&se=2021-08-10T07%3A13%3A25Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/all.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/all.log?sv=2019-07-07&sr=b&sig=F8Br1YpqDkM1%2FT8n0UHvbRlkSbV%2Fhf16hNG%2BEZaXwhk%3D&st=2021-08-09T23%3A03%3A25Z&se=2021-08-10T07%3A13%3A25Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.enter_contexts.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=z7Q4UT3lsWU0ccHzMh7AIhQQiUtaxpPy0r25XD0itm4%3D&st=2021-08-09T23%3A03%3A25Z&se=2021-08-10T07%3A13%3A25Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=LyBUsENhN35xpzT8JlOPKUfOUFKHQB4udBNVfsZoDfg%3D&st=2021-08-09T23%3A03%3A25Z&se=2021-08-10T07%3A13%3A25Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.3e536e68-3c50-47bc-b0cd-64571614fbe9/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=zGRQGcey8qFpstRYe7OSegQgaR03WVspXKZcD7mDXM8%3D&st=2021-08-09T23%3A03%3A26Z&se=2021-08-10T07%3A13%3A26Z&sp=r'}, 'submittedBy': 'Maggie Mhanna'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: 0ca0d3c5-1c82-45ad-a059-b711a7ee95f9\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Deploy ) Status: NotStarted\n",
      "StepRun( Deploy ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "========================================================================================================================\n",
      "2021-08-09T23:13:47Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-08-09T23:13:47Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore\n",
      "2021-08-09T23:13:48Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/caches/lis_artifacts --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/configs/lis_artifacts.cfg --log-level=LOG_WARNING\n",
      "2021-08-09T23:13:48Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts\n",
      "2021-08-09T23:13:48Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-08-09T23:13:48Z Starting output-watcher...\n",
      "2021-08-09T23:13:48Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-08-09T23:13:49Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-09T23:13:49Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      "Digest: sha256:64071389a06820223142eabd61e1b4bfd5e0b450131c8a50eef3c745fad8a73e\n",
      "Status: Image is up to date for 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff:latest\n",
      "29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff:latest\n",
      "2021-08-09T23:13:49Z Check if container 0ca0d3c5-1c82-45ad-a059-b711a7ee95f9 already exist exited with 0, \n",
      "\n",
      "8fb2e024d644bfefd8f2227c156898b930ecc645c87a1bef5e15366e37ca0f97\n",
      "2021-08-09T23:13:49Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-09T23:13:49Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-53637be0e8df04b49ecbe56deb860808-6f173cd39f6d883e-01 -sshRequired=false] \n",
      "2021/08/09 23:13:49 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/09 23:13:49 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/09 23:13:49 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/09 23:13:49 Starting infiniband setup\n",
      "2021/08/09 23:13:49 Python Version found is Python 3.6.9 :: Anaconda, Inc.\n",
      "\n",
      "2021/08/09 23:13:49 Returning Python Version as 3.6\n",
      "2021-08-09T23:13:49Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/09 23:13:49 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/09 23:13:49 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/09 23:13:49 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-08-09T23:13:49Z Not setting up Infiniband in Container\n",
      "2021/08/09 23:13:49 Not setting up Infiniband in Container\n",
      "2021/08/09 23:13:49 Not setting up Infiniband in Container\n",
      "2021/08/09 23:13:49 Python Version found is Python 3.6.9 :: Anaconda, Inc.\n",
      "\n",
      "2021/08/09 23:13:49 Returning Python Version as 3.6\n",
      "2021/08/09 23:13:49 sshd inside container not required for job, skipping setup.\n",
      "2021/08/09 23:13:50 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/09 23:13:50 App Insight Client has already been closed\n",
      "2021/08/09 23:13:50 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-09T23:13:50Z Starting docker container succeeded.\n",
      "2021-08-09T23:13:53Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/08/09 23:13:47 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/08/09 23:13:47 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      ">>>   2021/08/09 23:13:47 runtime.GOOS linux\n",
      ">>>   2021/08/09 23:13:47 Checking if '/tmp' exists\n",
      ">>>   2021/08/09 23:13:47 Reading dyanamic configs\n",
      ">>>   2021/08/09 23:13:47 Container sas url: https://baiscriptswesteuropeprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=9UBH7ig8b9NIeIkNQpNxDmP7wUMtSqFoIE5AY22cheE%3D\n",
      ">>>   2021/08/09 23:13:47 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n",
      ">>>   2021/08/09 23:13:47 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: true. Is Azsecpack installation enabled: false,\n",
      ">>>   2021/08/09 23:13:47 Starting Azsecpack installation on machine: f585a493cfbe4c568aa6cd957b0778e8000000#72f988bf-86f1-41af-91ab-2d7cd011db47#2f091423-f84d-4062-8e67-1437a0c50045#lis#lis-ml#pipeline-cluster#tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d\n",
      ">>>   2021/08/09 23:13:47 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n",
      ">>>   2021/08/09 23:13:47 Turning off azsecpack, if it is already running\n",
      ">>>   2021/08/09 23:13:47 [doTurnOffAzsecpack] output:Unit mdsd.service could not be found.\n",
      ">>>   ,err:exit status 1.\n",
      ">>>   2021/08/09 23:13:47 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/08/09 23:13:47 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/08/09 23:13:47 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/09 23:13:47 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/09 23:13:47 GPU count found on the node: 1\n",
      ">>>   2021/08/09 23:13:47 Mellanox Inbox drivers found (implying presence of SR-IOV)?: false\n",
      ">>>   2021/08/09 23:13:47 Disabling IB for NCCL.\n",
      ">>>   2021/08/09 23:13:47 AMLComputeXDSEndpoint:  https://westeurope-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/08/09 23:13:47 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/08/09 23:13:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/config\n",
      ">>>   2021/08/09 23:13:47 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/08/09 23:13:47 Starting identity responder.\n",
      ">>>   2021/08/09 23:13:47 Starting identity responder.\n",
      ">>>   2021/08/09 23:13:47 Logfile used for identity responder: /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/IdentityResponderLog-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:13:47 Logfile used for identity responder: /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/IdentityResponderLog-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:13:47 Started Identity Responder for job.\n",
      ">>>   2021/08/09 23:13:47 Started Identity Responder for job.\n",
      ">>>   2021/08/09 23:13:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd\n",
      ">>>   2021/08/09 23:13:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/shared\n",
      ">>>   2021/08/09 23:13:47 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/08/09 23:13:47 Mounting job level file systems\n",
      ">>>   2021/08/09 23:13:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts\n",
      ">>>   2021/08/09 23:13:47 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/08/09 23:13:47 Datastore credentials file not found, skipping.\n",
      ">>>   2021/08/09 23:13:47 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/config/.master.runtimesastokens\n",
      ">>>   2021/08/09 23:13:47 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/08/09 23:13:47 Mounting NFS servers\n",
      ">>>   2021/08/09 23:13:47 No Azure File Shares configured\n",
      ">>>   2021/08/09 23:13:47 Mounting blob file systems\n",
      ">>>   2021/08/09 23:13:47 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/08/09 23:13:47 Mounting azureml-blobstore-29bfa99a-8943-410c-8e02-10fa3a3417f5 container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore\n",
      ">>>   2021/08/09 23:13:47 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/09 23:13:47 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/09 23:13:47 Blobfuse cache size set to 312241 MB.\n",
      ">>>   2021/08/09 23:13:47 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/08/09 23:13:47 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore\n",
      ">>>   2021/08/09 23:13:47 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore\n",
      ">>>   2021/08/09 23:13:48 Successfully mounted azureml-blobstore-29bfa99a-8943-410c-8e02-10fa3a3417f5 container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore\n",
      ">>>   2021/08/09 23:13:48 Failed to created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9, due to mkdir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9: read-only file system\n",
      ">>>   2021/08/09 23:13:48 Mounting lis-artifacts container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts\n",
      ">>>   2021/08/09 23:13:48 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/09 23:13:48 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/09 23:13:48 Blobfuse cache size set to 312241 MB.\n",
      ">>>   2021/08/09 23:13:48 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/caches/lis_artifacts --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312241 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/configs/lis_artifacts.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/08/09 23:13:48 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts\n",
      ">>>   2021/08/09 23:13:48 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts\n",
      ">>>   2021/08/09 23:13:48 Successfully mounted lis-artifacts container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts\n",
      ">>>   2021/08/09 23:13:48 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9\n",
      ">>>   2021/08/09 23:13:48 No unmanaged file systems configured\n",
      ">>>   2021/08/09 23:13:48 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/09 23:13:48 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/09 23:13:48 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      ">>>   2021/08/09 23:13:48 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      ">>>   2021/08/09 23:13:48 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/08/09 23:13:48 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9\n",
      ">>>   2021/08/09 23:13:48 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9\n",
      ">>>   2021/08/09 23:13:48 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9\n",
      ">>>   2021/08/09 23:13:48 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9\n",
      ">>>   2021/08/09 23:13:48 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs\n",
      ">>>   2021/08/09 23:13:48 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d\n",
      ">>>   2021/08/09 23:13:48 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:13:48 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9\n",
      ">>>   2021/08/09 23:13:48 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs\n",
      ">>>   2021/08/09 23:13:48 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs\n",
      ">>>   2021/08/09 23:13:48 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs\n",
      ">>>   2021/08/09 23:13:48 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d\n",
      ">>>   2021/08/09 23:13:48 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:13:48 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs\n",
      ">>>   2021/08/09 23:13:48 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs\n",
      ">>>   2021/08/09 23:13:48 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/outputs\n",
      ">>>   2021/08/09 23:13:48 Starting output-watcher...\n",
      ">>>   2021/08/09 23:13:48 Single file input dataset is enabled.\n",
      ">>>   2021/08/09 23:13:48 Start to pulling docker image: 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      ">>>   2021/08/09 23:13:48 Start pull docker image: 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io\n",
      ">>>   2021/08/09 23:13:48 Getting credentials for image 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff with url 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io\n",
      ">>>   2021/08/09 23:13:48 Container registry is ACR.\n",
      ">>>   2021/08/09 23:13:48 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/08/09 23:13:48 Getting ACR Credentials from EMS for environment pipeline-env:Autosave_2021-08-09T13:40:51Z_738b2e1a\n",
      ">>>   2021/08/09 23:13:48 Requesting XDS for registry details.\n",
      ">>>   2021/08/09 23:13:48 Attempt 1 of http call to https://westeurope-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourceGroups/lis/workspaces/lis-ml/clusters/pipeline-cluster/nodes/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d?api-version=2018-02-01\n",
      ">>>   2021/08/09 23:13:49 Got container registry details from credentials service for registry address: 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io.\n",
      ">>>   2021/08/09 23:13:49 Writing ACR Details to file...\n",
      ">>>   2021/08/09 23:13:49 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/08/09 23:13:49 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/08/09 23:13:49 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/08/09 23:13:49 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/08/09 23:13:49 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/08/09 23:13:49 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/08/09 23:13:49 EMS returned 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io for environment pipeline-env\n",
      ">>>   2021/08/09 23:13:49 Save docker credentials for image 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff in /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/docker_login_B90A26940143B351\n",
      ">>>   2021/08/09 23:13:49 Start login to the docker registry\n",
      ">>>   2021/08/09 23:13:49 Successfully logged into the docker registry.\n",
      ">>>   2021/08/09 23:13:49 Start run pull docker image command\n",
      ">>>   2021/08/09 23:13:49 Pull docker image succeeded.\n",
      ">>>   2021/08/09 23:13:49 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/docker_login_B90A26940143B351\n",
      ">>>   2021/08/09 23:13:49 Pull docker image time: 425.090955ms\n",
      ">>>   \n",
      ">>>   2021/08/09 23:13:49 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/09 23:13:49 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/09 23:13:49 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/09 23:13:49 Setting the memory limit for docker container to be 55987 MB\n",
      ">>>   2021/08/09 23:13:49 The env variable file size is 41546 bytes\n",
      ">>>   2021/08/09 23:13:49 Creating parent cgroup '0ca0d3c5-1c82-45ad-a059-b711a7ee95f9' for Containers used in Job\n",
      ">>>   2021/08/09 23:13:49 Add parent cgroup '0ca0d3c5-1c82-45ad-a059-b711a7ee95f9' to container '0ca0d3c5-1c82-45ad-a059-b711a7ee95f9'\n",
      ">>>   2021/08/09 23:13:49 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/08/09 23:13:49 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,0ca0d3c5-1c82-45ad-a059-b711a7ee95f9,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,--gpus,all,-m,55987m,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/config/.batchai.envlist,--cgroup-parent=/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/,--shm-size,2g\n",
      ">>>   2021/08/09 23:13:49 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/08/09 23:13:49 the binding /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9 \n",
      ">>>   2021/08/09 23:13:49 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,0ca0d3c5-1c82-45ad-a059-b711a7ee95f9,--gpus,all,-m,55987m,-w,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/config/.batchai.envlist,--cgroup-parent=/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/wd,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/certs\n",
      ">>>   2021/08/09 23:13:49 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 0ca0d3c5-1c82-45ad-a059-b711a7ee95f9 --gpus all -m 55987m -w /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/config/.batchai.envlist --cgroup-parent=/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9 -v /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/wd -v /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/certs -d -it --privileged --net=host 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      ">>>   2021/08/09 23:13:49 Check if container 0ca0d3c5-1c82-45ad-a059-b711a7ee95f9 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/08/09 23:13:49 Check if container 0ca0d3c5-1c82-45ad-a059-b711a7ee95f9 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/08/09 23:13:49 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/09 23:13:49 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/09 23:13:49 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-53637be0e8df04b49ecbe56deb860808-6f173cd39f6d883e-01 -sshRequired=false] \n",
      ">>>   2021/08/09 23:13:49 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-53637be0e8df04b49ecbe56deb860808-6f173cd39f6d883e-01 -sshRequired=false] \n",
      ">>>   2021/08/09 23:13:50 Container ssh is not required for job type.\n",
      ">>>   2021/08/09 23:13:50 Starting docker container succeeded.\n",
      ">>>   2021/08/09 23:13:50 Starting docker container succeeded.\n",
      ">>>   2021/08/09 23:13:50 Disk space after starting docker container: 319574MB\n",
      ">>>   2021/08/09 23:13:50 Begin execution of runSpecialJobTask\n",
      ">>>   2021/08/09 23:13:50 Creating directory at $AZUREML_LOGDIRECTORY_PATH\n",
      ">>>   2021/08/09 23:13:50 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml-logs\n",
      ">>>   2021/08/09 23:13:50 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs\n",
      ">>>   2021/08/09 23:13:50 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8675f058-2d6d-4f4e-a69b-b2c31232dd94\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/09 23:13:50 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:13:50 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml_compute_logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/09 23:13:50 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9;/azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8675f058-2d6d-4f4e-a69b-b2c31232dd94\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/09 23:13:50 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/08/09 23:13:50 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-53637be0e8df04b49ecbe56deb860808-95296e2a4dfccc34-01 -t 0ca0d3c5-1c82-45ad-a059-b711a7ee95f9 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/0ca0d3c5-1c82-45ad-a_bfb4cf4c-7988-4e8c-bda2-858d94ae732b/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9;/azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/workspaceblobstore/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8675f058-2d6d-4f4e-a69b-b2c31232dd94\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/09 23:13:52 Attempt 1 of http call to https://westeurope.api.azureml.ms/history/v1.0/private/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourceGroups/lis/providers/Microsoft.MachineLearningServices/workspaces/lis-ml/runs/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/spans\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:50.883055] Entering job preparation.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.271880] Starting job preparation.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.271917] Extracting the control code.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.272215] Starting extract_project.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.272256] Starting to extract zip file.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.293058] Finished extracting zip file.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.295988] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.296028] Start fetching snapshots.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.296062] Start fetching snapshot.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.296075] Retrieving project from snapshot: 8675f058-2d6d-4f4e-a69b-b2c31232dd94\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 45\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.794627] Finished fetching snapshot.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.794656] Finished fetching snapshots.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.794666] Finished extract_project.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.794751] Finished fetching and extracting the control code.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.797727] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.798568] Start run_history_prep.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:52.810357] Entering context manager injector.\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: Acquired lockfile /tmp/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9-datastore.lock to downloading input data references\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:53.250855] downloadDataStore completed\n",
      ">>>   2021/08/09 23:13:53 runSpecialJobTask: preparation: [2021-08-09T23:13:53.253396] Job preparation is complete.\n",
      ">>>   2021/08/09 23:13:53 Execution of runSpecialJobTask completed\n",
      ">>>   2021/08/09 23:13:53 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/08/09 23:13:53 Process Exiting with Code:  0\n",
      ">>>   2021/08/09 23:13:53 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      ">>>   \n",
      "2021-08-09T23:13:53Z 127.0.0.1 slots=1 max-slots=1\n",
      "2021-08-09T23:13:53Z launching Custom job\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/08/09 23:13:53 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/08/09 23:13:53 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/09 23:13:53 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/08/09 23:13:53 Send process info logs to master server succeeded\n",
      "2021/08/09 23:13:53 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/09 23:13:53 Send process info logs to master server succeeded\n",
      "[2021-08-09T23:13:53.920493] Entering context manager injector.\n",
      "[2021-08-09T23:13:54.386839] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['lis_components/deploy/deploy.py', '--service_name', 'lis-gpt2-serviceapp', '--model_name', 'lis-gpt2-model', '--cpu_cores', '1', '--memory_gb', '2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/register_deploy_link'])\n",
      "Script type = None\n",
      "[2021-08-09T23:13:54.390438] Entering Run History Context Manager.\n",
      "[2021-08-09T23:13:55.046206] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/wd/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9\n",
      "[2021-08-09T23:13:55.046433] Preparing to call script [lis_components/deploy/deploy.py] with arguments:['--service_name', 'lis-gpt2-serviceapp', '--model_name', 'lis-gpt2-model', '--cpu_cores', '1', '--memory_gb', '2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/register_deploy_link']\n",
      "[2021-08-09T23:13:55.046462] After variable expansion, calling script [lis_components/deploy/deploy.py] with arguments:['--service_name', 'lis-gpt2-serviceapp', '--model_name', 'lis-gpt2-model', '--cpu_cores', '1', '--memory_gb', '2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/mounts/lis_artifacts/azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/register_deploy_link']\n",
      "\n",
      "lis-gpt2-model version 1\n",
      "2021/08/09 23:13:58 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-09 23:14:00+00:00 Creating Container Registry if not exists.\n",
      "2021-08-09 23:14:00+00:00 Registering the environment.\n",
      "2021-08-09 23:14:03+00:00 Building image.\n",
      "2021-08-09 23:19:47+00:00 Generating deployment configuration.\n",
      "2021-08-09 23:19:48+00:00 Submitting deployment to compute..\n",
      "2021-08-09 23:19:56+00:00 Checking the status of deployment lis-gpt2-serviceapp.\n",
      "2021-08-09 23:22:33+00:00 Checking the status of inference endpoint lis-gpt2-serviceapp.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "\n",
      "\n",
      "[2021-08-09T23:22:38.028351] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "6 items cleaning up...\n",
      "Cleanup took 0.44548845291137695 seconds\n",
      "[2021-08-09T23:22:38.625214] Finished context manager injector.\n",
      "2021/08/09 23:22:39 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/09 23:22:39 Send process info logs to master server succeeded\n",
      "2021/08/09 23:22:39 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 2\n",
      "FilteredData: 0.\n",
      "2021/08/09 23:22:39 Process Exiting with Code:  0\n",
      "2021/08/09 23:22:39 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "===============================================================================================================\n",
      "[2021-08-09T23:22:40.123502] Entering job release\n",
      "[2021-08-09T23:22:40.991222] Starting job release\n",
      "[2021-08-09T23:22:40.991748] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 166\n",
      "[2021-08-09T23:22:40.991999] job release stage : upload_datastore starting...\n",
      "[2021-08-09T23:22:40.992300] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-08-09T23:22:40.992512] job release stage : execute_job_release starting...\n",
      "[2021-08-09T23:22:40.994613] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-08-09T23:22:40.994914] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-08-09T23:22:41.002416] Entering context manager injector.\n",
      "[2021-08-09T23:22:41.023373] job release stage : upload_datastore completed...\n",
      "[2021-08-09T23:22:41.102785] job release stage : send_run_telemetry starting...\n",
      "[2021-08-09T23:22:41.115561] get vm size and vm region successfully.\n",
      "[2021-08-09T23:22:41.122052] get compute meta data successfully.\n",
      "[2021-08-09T23:22:41.236688] job release stage : execute_job_release completed...\n",
      "[2021-08-09T23:22:41.386953] post artifact meta request successfully.\n",
      "[2021-08-09T23:22:41.459524] upload compute record artifact successfully.\n",
      "[2021-08-09T23:22:41.459608] job release stage : send_run_telemetry completed...\n",
      "[2021-08-09T23:22:41.459887] Job release is complete\n",
      "\n",
      "StepRun(Deploy) Execution Summary\n",
      "==================================\n",
      "StepRun( Deploy ) Status: Finished\n",
      "{'runId': '0ca0d3c5-1c82-45ad-a059-b711a7ee95f9', 'target': 'pipeline-cluster', 'status': 'Completed', 'startTimeUtc': '2021-08-09T23:13:46.680396Z', 'endTimeUtc': '2021-08-09T23:22:49.346829Z', 'properties': {'ContentSnapshotId': '8675f058-2d6d-4f4e-a69b-b2c31232dd94', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '0ac4e4a0-8edc-497f-a572-a64a8ac862b6', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '25177c8c', 'azureml.pipelinerunid': 'f29233bb-ae00-4b8c-bf50-7e1cd833cd29', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.RuntimeType': 'Hosttools'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'lis_components/deploy/deploy.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--service_name', '$AML_PARAMETER_aml_service_name', '--model_name', '$AML_PARAMETER_aml_model_name', '--cpu_cores', '$AML_PARAMETER_cpu_cores', '--memory_gb', '$AML_PARAMETER_memory_gb', '--register_deploy_link', '$AZUREML_DATAREFERENCE_register_deploy_link'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'pipeline-cluster', 'dataReferences': {'register_deploy_link': {'dataStoreName': 'lis_artifacts', 'mode': 'Mount', 'pathOnDataStore': 'azureml/3e536e68-3c50-47bc-b0cd-64571614fbe9/register_deploy_link', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'pipeline-env', 'version': 'Autosave_2021-08-09T13:40:51Z_738b2e1a', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.9', 'pip', {'pip': ['transformers == 3.5.1', 'datasets == 1.10.2', 'tensorflow == 2.5.0', 'azureml-defaults==1.30.0']}], 'name': 'azureml_82f5617ca19cd57b18cafd61c017ea7a'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210531.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': 'westus2', 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard'}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_aml_service_name': 'lis-gpt2-serviceapp', 'AML_PARAMETER_aml_model_name': 'lis-gpt2-model', 'AML_PARAMETER_cpu_cores': '1', 'AML_PARAMETER_memory_gb': '2'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=5faWz%2FlY0LkmlFVPf7wC9i1BqEItQzwmbza96fDfwU0%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=hqLFarpUksLS9EMLaXNGwvGa66jbbH539DIh4hlotd0%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=2vsNWgEtauy0hhbXHNsV%2B%2Fw4OABSXR4B07rq3EdGnac%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=KGF73mPtqtMt9xiJ8x30pAM1ZdwNsOOXdVMcWViN9Ms%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'azureml-logs/process_info.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=iK2bVh06SSY5jXmqRpG9M0vromwZhSJ0Ka402xUOctk%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'azureml-logs/process_status.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=wLWC3rxdwiCSkgTS9p7LCchmCD9A48YhHX5o9pZ3ops%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'logs/azureml/103_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/103_azureml.log?sv=2019-07-07&sr=b&sig=dy%2FwfZefEF0cmnMDyE9nVyPnEt1obD58AuKXh1pMScg%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=K7Np0UE7MXH7aNdgk7acnUSHjTFN0HC34SGAczPHkvM%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=OIgk8LlhMG%2FmPlyyVejSRj2Ywl31R%2Fyua4hxsq9ZMGQ%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=L6b3OK6zu27ySJg9hlNCnnkE%2B3GouH%2BGrIWPNBLQ4OU%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=a3Wua6w9jdgs8IbnxULqcCOJaU%2FRvgVvZjrmMfTPBdk%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.0ca0d3c5-1c82-45ad-a059-b711a7ee95f9/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=1plw%2B9R2azU8NKl6v231j4zshG79%2FLjTCaiZgoQL0m0%3D&st=2021-08-09T23%3A12%3A43Z&se=2021-08-10T07%3A22%3A43Z&sp=r'}, 'submittedBy': 'Maggie Mhanna'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'f29233bb-ae00-4b8c-bf50-7e1cd833cd29', 'status': 'Completed', 'startTimeUtc': '2021-08-09T23:09:20.660593Z', 'endTimeUtc': '2021-08-09T23:22:52.066876Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"num_train_epochs\":\"1\",\"aml_model_name\":\"lis-gpt2-model\",\"aml_service_name\":\"lis-gpt2-serviceapp\",\"cpu_cores\":\"1\",\"memory_gb\":\"2\"}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.f29233bb-ae00-4b8c-bf50-7e1cd833cd29/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=K4EA9wbNDdgeIjZL2%2Fc5xRL9A2iqd8poJ49Yo5chh0g%3D&st=2021-08-09T23%3A07%3A28Z&se=2021-08-10T07%3A17%3A28Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.f29233bb-ae00-4b8c-bf50-7e1cd833cd29/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=7pfEfk%2BFaTdDt%2Bra99VdcNF7V8HzaakcWi8pt07efc4%3D&st=2021-08-09T23%3A07%3A28Z&se=2021-08-10T07%3A17%3A28Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.f29233bb-ae00-4b8c-bf50-7e1cd833cd29/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=wUSC%2Bm2AIWNqhw2HPjSZB7wINLCTTr3nN6y5yIs8fWE%3D&st=2021-08-09T23%3A07%3A28Z&se=2021-08-10T07%3A17%3A28Z&sp=r'}, 'submittedBy': 'Maggie Mhanna'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an experiment and run the pipeline\n",
    "\n",
    "experiment = Experiment(workspace = ws, name = 'lis-ct-pipeline')\n",
    "\n",
    "pipeline_parameters = {\"num_train_epochs\": 1,\n",
    "                       \"aml_model_name\": \"lis-gpt2-model\",\n",
    "                       \"aml_service_name\": \"lis-gpt2-serviceapp\",\n",
    "                       \"cpu_cores\": 1,\n",
    "                       \"memory_gb\": 2,                       \n",
    "                       }\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline, \n",
    "                                 pipeline_parameters=pipeline_parameters)\n",
    "\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055ad91",
   "metadata": {},
   "source": [
    "# Consume Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5798942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'Hello have a fantastic day @Nagpur.\"\\n\\nAt the time, she was on vacation in Switzerland.\\n.@NagaKi', '2': 'Hello, what a shame, if my brother is in the hospital? Are you still the kind of guy who gives us hope?\" Marge giggled', '3': 'Hello\\n\\nGreetings\\n', '4': 'Hello and thank you all for your support!!!', '5': \"Hello in the past. I am glad if your name wasn't mentioned in this comment. This guy started with my wife's name and he's done\"}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "data = {\"data\":\"Hello\"\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'http://f87c9bb3-aded-45e3-99d8-e9de9bad63f8.westeurope.azurecontainer.io/score'\n",
    "api_key = '' # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(json.loads(json.loads(result)))\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
